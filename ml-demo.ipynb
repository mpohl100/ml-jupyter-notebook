{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5baa1a4e",
   "metadata": {},
   "source": [
    "# Building software to automate engineering the architecture of neural networks\n",
    "This notebook demonstrates how we try to provide automation for the job of the machine learning engineer.\n",
    "The idea is that the machine learning engineer provides an initial structure of the neural network they want to train\n",
    "and then starts our software overnight which tries to improve the accuracy of the neural network by applying mutations to the structure of the network. The traits of the successful mutations are distributed to the next generation of neural networks and through the same mechanism that life uses the fitter neural network structures survive. This is called a genetic algorithm.\n",
    "\n",
    "## Motivation: The what?\n",
    "This project aims to figure whether genetic algorithms are suitable as automatic neural network improvement tool.\n",
    "\n",
    "## How do we try to achieve this?\n",
    "I elected Rust as the programming language to implement a proof of concept of the idea.\n",
    "This notebook aims to give you an overview of what has been implemented so far and how the software can be used for training a neural network on data.\n",
    "With the example of the MNIST data set (28x28 pixel images of the numbers 0 to 9) the usage of our machine learning suite shall be demoed.\n",
    "We use python as the umbrella tool to prepare this notebook for training a neural network on the MNIST data set.\n",
    "\n",
    "## Structure of the notebook\n",
    "\n",
    "### Step 1: Preparing the MNIST data set.\n",
    "The goal of this step is to transform the pixel data and their labels to two files:\n",
    "- input.csv: all the pixel data is transformed to one floating point value per pixel (0.0 for white 1.0 for black). One line contains the data of one image\n",
    "- target.csv: the label of the image on the corresponding line in input.csv. It is structured as a vector of 10 values with one one and nine zeros. The index of the one is the number that is displayed on the image.\n",
    "\n",
    "## Step 2: Install Rust machine learning library\n",
    "For running this notebook cell you must have Rust installed. It is the easiest to use the dev container, that way the installation is automated for you.\n",
    "\n",
    "### Step 3: Doing an initial training on the data set\n",
    "The structure in the file nn_shape.yaml tells the Rust executable train what shape of the neural network to prepare. A training is started by copy pasting the command printed in the cell output to the Ubuntu shell.\n",
    "You can find more documentation on how the shape file has to be structured in the README of the Rust machine learning repository here \n",
    "[Check out my machine learning project in Rust on GitHub](https://github.com/mpohl100/ml_rust)\n",
    "\n",
    "\n",
    "### Step 4: Evolve the shape of the neural network\n",
    "The created neural network of step 2 is used to breed an initial generation of neural networks to train with the MNIST data. The neural networks with the best results get to spread the traits of their shapes for the next generation. The algorithm repeats for the number of generations you specify as command line parameter.\n",
    "\n",
    "## Conclusion\n",
    "You don't need to completely run the software or wait until the end. The idea is to familiarize you with the project.\n",
    "If this approach is something that interests you I am happy to get in contact with you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f3504",
   "metadata": {},
   "source": [
    "## Step 1: Preparing the MNIST data set\n",
    "Running this cell is essential if you want to run the software on your machine. It prepares the MNIST data set and demonstrates how to prepare data for the use with our machine learning suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a41b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Resize images to 16x16 (256 pixels)\n",
    "x_train = x_train[:, ::2, ::2]  # Downsample by skipping every other pixel\n",
    "x_test = x_test[:, ::2, ::2]\n",
    "\n",
    "# Normalize pixel values to range [0.0, 1.0] (0.0 for white, 1.0 for black)\n",
    "x_train = 1 - x_train / 255.0\n",
    "x_test = 1 - x_test / 255.0\n",
    "\n",
    "# Flatten images into 256-pixel vectors\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Convert targets to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)\n",
    "\n",
    "# Save input data to input.csv\n",
    "input_df = pd.DataFrame(x_train_flat)\n",
    "input_df.to_csv(\"input.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "# Save target data to target.csv\n",
    "target_df = pd.DataFrame(y_train_onehot)\n",
    "target_df.to_csv(\"target.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Saved input.csv and target.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961106e9",
   "metadata": {},
   "source": [
    "## Step 2: Install Rust machine learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone github.com/mpohl100/ml_rust and cargo build --release\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def clone_and_build(repo_url, branch=\"main\"):\n",
    "    \"\"\"\n",
    "    Clones a GitHub repository and runs `cargo build --release`.\n",
    "\n",
    "    Args:\n",
    "        repo_url (str): The GitHub repository URL to clone.\n",
    "        branch (str): The branch to checkout. Default is \"main\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract repository name from URL\n",
    "        repo_name = repo_url.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "        \n",
    "        # Check if the repository already exists\n",
    "        if not os.path.exists(repo_name):\n",
    "            print(f\"Cloning {repo_url} into {os.getcwd()}...\")\n",
    "            subprocess.run(\n",
    "                [\"git\", \"clone\", \"--branch\", branch, repo_url],\n",
    "                check=True\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Repository {repo_name} already exists. Skipping clone.\")\n",
    "            # do a git pull\n",
    "            os.chdir(repo_name)\n",
    "            print(\"Running `git pull`...\")\n",
    "            subprocess.run([\"git\", \"pull\"], check=True)\n",
    "            os.chdir(\"..\")\n",
    "\n",
    "        # Change into the repository directory\n",
    "        repo_path = os.path.join(os.getcwd(), repo_name)\n",
    "        os.chdir(repo_path)\n",
    "\n",
    "        # Run `cargo build --release`\n",
    "        print(\"Running `cargo build --release`...\")\n",
    "        subprocess.run([\"cargo\", \"build\", \"--release\"], check=True)\n",
    "\n",
    "        print(\"Build completed successfully!\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while executing a command: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Change back to the original directory\n",
    "        os.chdir(\"..\")\n",
    "\n",
    "repo_url = \"https://github.com/mpohl100/ml_rust.git\"\n",
    "clone_and_build(repo_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed74097",
   "metadata": {},
   "source": [
    "## Step 3: Doing an initial training on the data set\n",
    "Running the cell prepares the shell command for you. please copy paste it and run it in your shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for `nn_generator`\n",
    "model_directory = \"./trained_model\"\n",
    "# create the trained model directory\n",
    "import os\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "input_file = \"input.csv\"\n",
    "target_file = \"target.csv\"\n",
    "shape_file = \"nn_shape.yaml\"\n",
    "validation_split = 0.7\n",
    "learning_rate = 0.05\n",
    "epochs = 10\n",
    "tolerance = 0.2\n",
    "batch_size = 32\n",
    "use_adam = True\n",
    "\n",
    "# Create the command for training the neural network\n",
    "command = [\n",
    "    \"./ml_rust/target/release/train\",\n",
    "    \"--model-directory\", model_directory,\n",
    "    \"--input-file\", input_file,\n",
    "    \"--target-file\", target_file,\n",
    "    \"--shape-file\", shape_file,\n",
    "    \"--validation-split\", str(validation_split),\n",
    "    \"--learning-rate\", str(learning_rate),\n",
    "    \"--epochs\", str(epochs),\n",
    "    \"--tolerance\", str(tolerance),\n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--use-adam\" if use_adam else \"\"\n",
    "]\n",
    "\n",
    "#print the command\n",
    "print(\" \".join(command))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708ac4e",
   "metadata": {},
   "source": [
    "## Step 4: Evolve the shape of the neural network\n",
    "This cell prepares the command you need to paste to your shell and run in order to do automated neural network improving.\n",
    "This command is added for demonstration purposes, it will take a couple of hours to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for `nn_generator`\n",
    "model_directory = \"./trained_model\"\n",
    "# create the trained model directory\n",
    "import os\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "input_file = \"input.csv\"\n",
    "target_file = \"target.csv\"\n",
    "nb_threads = 4\n",
    "validation_split = 0.7\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "tolerance = 0.1\n",
    "batch_size = 32\n",
    "use_adam = True\n",
    "num_generations = 100\n",
    "log_level = 1\n",
    "population_size = 4\n",
    "num_offsprings = 10\n",
    "\n",
    "# Create the command for training the neural network\n",
    "command = [\n",
    "    \"./ml_rust/target/release/nn_generator\",\n",
    "    \"--model-directory\", model_directory,\n",
    "    \"--input-file\", input_file,\n",
    "    \"--target-file\", target_file,\n",
    "    \"--nb-threads\", str(nb_threads),\n",
    "    \"--validation-split\", str(validation_split),\n",
    "    \"--learning-rate\", str(learning_rate),\n",
    "    \"--epochs\", str(epochs),\n",
    "    \"--tolerance\", str(tolerance),\n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--use-adam\" if use_adam else \"\",\n",
    "    \"--num-generations\", str(num_generations),\n",
    "    \"--log-level\", str(log_level),\n",
    "    \"--population-size\", str(population_size),\n",
    "    \"--num-offsprings\", str(num_offsprings)\n",
    "]\n",
    "\n",
    "#print the command\n",
    "print(\" \".join(command))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
