{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5baa1a4e",
   "metadata": {},
   "source": [
    "# MNIST Dataset Processing and Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a41b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:38:33.185467: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-07 10:38:33.189243: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-07 10:38:33.200164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733567913.220071    1063 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733567913.225277    1063 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 10:38:33.247494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7a49b",
   "metadata": {},
   "source": [
    "## Step 1: Download and Process MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a423b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Resize images to 16x16 (256 pixels)\n",
    "x_train = x_train[:, ::2, ::2]  # Downsample by skipping every other pixel\n",
    "x_test = x_test[:, ::2, ::2]\n",
    "\n",
    "# Normalize pixel values to range [0.0, 1.0] (0.0 for white, 1.0 for black)\n",
    "x_train = 1 - x_train / 255.0\n",
    "x_test = 1 - x_test / 255.0\n",
    "\n",
    "# Flatten images into 256-pixel vectors\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Convert targets to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed3dd7",
   "metadata": {},
   "source": [
    "## Step 2: Save Processed Data to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acefa21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input.csv and target.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save input data to input.csv\n",
    "input_df = pd.DataFrame(x_train_flat)\n",
    "input_df.to_csv(\"input.csv\", index=False)\n",
    "\n",
    "# Save target data to target.csv\n",
    "target_df = pd.DataFrame(y_train_onehot)\n",
    "target_df.to_csv(\"target.csv\", index=False)\n",
    "\n",
    "print(\"Saved input.csv and target.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708ac4e",
   "metadata": {},
   "source": [
    "## Step 3: Create a Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ddb6f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Tanh }] }\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 100\n",
      "Loss: 0.37950671970632377\n",
      "Epoch: 100\n",
      "Loss: 0.37950671970632377\n",
      "Epoch: 100\n",
      "Loss: 1.6913241645323618\n",
      "Epoch: 100\n",
      "Loss: 0.37950671970632377\n",
      "Epoch: 100\n",
      "Loss: 0.25611202584798515\n",
      "Epoch: 100\n",
      "Loss: 0.25611202584798515\n",
      "Epoch: 100\n",
      "Loss: 0.25611202584798515\n",
      "Epoch: 100\n",
      "Loss: 1.659660677832816\n",
      "Epoch: 100\n",
      "Loss: 0.23698305197050004\n",
      "Epoch: 100\n",
      "Loss: 0.23698305197050004\n",
      "Epoch: 100\n",
      "Loss: 0.23698305197050004\n",
      "Epoch: 100\n",
      "Loss: 1.6513927514272417\n",
      "Epoch: 100\n",
      "Loss: 0.2275583712099578\n",
      "Epoch: 100\n",
      "Loss: 0.2275583712099578\n",
      "Epoch: 100\n",
      "Loss: 0.2275583712099578\n",
      "Epoch: 100\n",
      "Loss: 1.6456738405104643\n",
      "Epoch: 100\n",
      "Loss: 0.22166524219084863\n",
      "Epoch: 100\n",
      "Loss: 0.22166524219084863\n",
      "Epoch: 100\n",
      "Loss: 0.22166524219084863\n",
      "Epoch: 100\n",
      "Loss: 1.6414422867767064\n",
      "Epoch: 100\n",
      "Loss: 0.21752659543164224\n",
      "Epoch: 100\n",
      "Loss: 0.21752659543164224\n",
      "Epoch: 100\n",
      "Loss: 0.21752659543164224\n",
      "Epoch: 100\n",
      "Loss: 1.6404925358575446\n",
      "Epoch: 100\n",
      "Loss: 0.21441094043957018\n",
      "Epoch: 100\n",
      "Loss: 0.21441094043957018\n",
      "Epoch: 100\n",
      "Loss: 0.21441094043957018\n",
      "Epoch: 100\n",
      "Loss: 0.21195434576024869\n",
      "Epoch: 100\n",
      "Loss: 1.639083367230673\n",
      "Epoch: 100\n",
      "Loss: 0.21195434576024869\n",
      "Epoch: 100\n",
      "Loss: 0.21195434576024869\n",
      "Epoch: 100\n",
      "Loss: 0.2099522409674381\n",
      "Epoch: 100\n",
      "Loss: 1.6402130790702258\n",
      "Epoch: 100\n",
      "Loss: 0.2099522409674381\n",
      "Epoch: 100\n",
      "Loss: 0.2099522409674381\n",
      "Epoch: 100\n",
      "Loss: 0.2082792992699609\n",
      "Epoch: 100\n",
      "Loss: 1.6363079813218153\n",
      "Epoch: 100\n",
      "Loss: 0.2082792992699609\n",
      "Epoch: 100\n",
      "Loss: 0.2082792992699609\n",
      "Epoch: 100\n",
      "Loss: 0.206853714597935\n",
      "Epoch: 100\n",
      "Loss: 1.6373136080337027\n",
      "Epoch: 100\n",
      "Loss: 0.206853714597935\n",
      "Epoch: 100\n",
      "Loss: 0.206853714597935\n",
      "Epoch: 100\n",
      "Loss: 0.20561945724300087\n",
      "Epoch: 100\n",
      "Loss: 1.6388917812900259\n",
      "Epoch: 100\n",
      "Loss: 0.20561945724300087\n",
      "Epoch: 100\n",
      "Loss: 0.20561945724300087\n",
      "Epoch: 100\n",
      "Loss: 0.20453668710729525\n",
      "Epoch: 100\n",
      "Loss: 1.6328715741630146\n",
      "Epoch: 100\n",
      "Loss: 0.20453668710729525\n",
      "Epoch: 100\n",
      "Loss: 0.20453668710729525\n",
      "Epoch: 100\n",
      "Loss: 0.20357621328339626\n",
      "Epoch: 100\n",
      "Loss: 1.6352756970090339\n",
      "Epoch: 100\n",
      "Loss: 0.20357621328339626\n",
      "Epoch: 100\n",
      "Loss: 0.20357621328339626\n",
      "Epoch: 100\n",
      "Loss: 0.20271611243067378\n",
      "Epoch: 100\n",
      "Loss: 0.20271611243067378\n",
      "Epoch: 100\n",
      "Loss: 1.635074273120222\n",
      "Epoch: 100\n",
      "Loss: 0.20271611243067378\n",
      "Epoch: 100\n",
      "Loss: 0.20193957145754804\n",
      "Epoch: 100\n",
      "Loss: 0.20193957145754804\n",
      "Epoch: 100\n",
      "Loss: 1.6351367149133673\n",
      "Epoch: 100\n",
      "Loss: 0.20193957145754804\n",
      "Epoch: 100\n",
      "Loss: 0.2012334610726017\n",
      "Epoch: 100\n",
      "Loss: 0.2012334610726017\n",
      "Epoch: 100\n",
      "Loss: 1.6364987457450353\n",
      "Epoch: 100\n",
      "Loss: 0.2012334610726017\n",
      "Epoch: 100\n",
      "Loss: 0.20058736458634327\n",
      "Epoch: 100\n",
      "Loss: 0.20058736458634327\n",
      "Epoch: 100\n",
      "Loss: 1.6330457142550494\n",
      "Epoch: 100\n",
      "Loss: 0.20058736458634327\n",
      "Epoch: 100\n",
      "Loss: 0.19999290033892086\n",
      "Epoch: 100\n",
      "Loss: 0.19999290033892086\n",
      "Epoch: 100\n",
      "Loss: 0.19999290033892086\n",
      "Epoch: 100\n",
      "Loss: 1.635652113133762\n",
      "Epoch: 100\n",
      "Loss: 0.1994432390020462\n",
      "Epoch: 100\n",
      "Loss: 0.1994432390020462\n",
      "Epoch: 100\n",
      "Loss: 0.1994432390020462\n",
      "Epoch: 100\n",
      "Loss: 1.6344600494030825\n",
      "Epoch: 100\n",
      "Loss: 0.19893275332755705\n",
      "Epoch: 100\n",
      "Loss: 0.19893275332755705\n",
      "Epoch: 100\n",
      "Loss: 0.19893275332755705\n",
      "Epoch: 100\n",
      "Loss: 1.6350929824853901\n",
      "Epoch: 100\n",
      "Loss: 0.19845675975202623\n",
      "Epoch: 100\n",
      "Loss: 0.19845675975202623\n",
      "Epoch: 100\n",
      "Loss: 0.19845675975202623\n",
      "Epoch: 100\n",
      "Loss: 1.63317564708029\n",
      "Epoch: 100\n",
      "Loss: 0.19801132484170425\n",
      "Epoch: 100\n",
      "Loss: 0.19801132484170425\n",
      "Epoch: 100\n",
      "Loss: 0.19801132484170425\n",
      "Epoch: 100\n",
      "Loss: 0.197593118241385\n",
      "Epoch: 100\n",
      "Loss: 1.6342663745199677\n",
      "Epoch: 100\n",
      "Loss: 0.197593118241385\n",
      "Epoch: 100\n",
      "Loss: 0.197593118241385\n",
      "Epoch: 100\n",
      "Loss: 0.19719929947240541\n",
      "Epoch: 100\n",
      "Loss: 1.6333634597004265\n",
      "Epoch: 100\n",
      "Loss: 0.19719929947240541\n",
      "Epoch: 100\n",
      "Loss: 0.19719929947240541\n",
      "Epoch: 100\n",
      "Loss: 0.19682742971464104\n",
      "Epoch: 100\n",
      "Loss: 1.635881289297886\n",
      "Epoch: 100\n",
      "Loss: 0.19682742971464104\n",
      "Epoch: 100\n",
      "Loss: 0.19682742971464104\n",
      "Epoch: 100\n",
      "Loss: 0.19647540227584065\n",
      "Epoch: 100\n",
      "Loss: 1.6336179363138719\n",
      "Epoch: 100\n",
      "Loss: 0.19647540227584065\n",
      "Epoch: 100\n",
      "Loss: 0.19647540227584065\n",
      "Epoch: 100\n",
      "Loss: 0.19614138721532884\n",
      "Epoch: 100\n",
      "Loss: 1.633107869908832\n",
      "Epoch: 100\n",
      "Loss: 0.19614138721532884\n",
      "Epoch: 100\n",
      "Loss: 0.19582378681642876\n",
      "Epoch: 100\n",
      "Loss: 0.19614138721532884\n",
      "Epoch: 100\n",
      "Loss: 1.635128327628914\n",
      "Epoch: 100\n",
      "Loss: 0.19582378681642876\n",
      "Epoch: 100\n",
      "Loss: 0.1955211994665458\n",
      "Epoch: 100\n",
      "Loss: 0.19582378681642876\n",
      "Epoch: 100\n",
      "Loss: 1.635009184844702\n",
      "Epoch: 100\n",
      "Loss: 0.1955211994665458\n",
      "Epoch: 100\n",
      "Loss: 0.1952323901209335\n",
      "Epoch: 100\n",
      "Loss: 0.1955211994665458\n",
      "Epoch: 100\n",
      "Loss: 1.634116273313654\n",
      "Epoch: 100\n",
      "Loss: 0.1952323901209335\n",
      "Epoch: 100\n",
      "Loss: 0.1949562659719045\n",
      "Epoch: 100\n",
      "Loss: 0.1952323901209335\n",
      "Epoch: 100\n",
      "Loss: 1.6350924447497115\n",
      "Epoch: 100\n",
      "Loss: 0.1949562659719045\n",
      "Epoch: 100\n",
      "Loss: 0.19469185627068328\n",
      "Epoch: 100\n",
      "Loss: 0.1949562659719045\n",
      "Epoch: 100\n",
      "Loss: 0.19469185627068328\n",
      "Epoch: 100\n",
      "Loss: 1.6324933811897189\n",
      "Epoch: 100\n",
      "Loss: 0.19443829548965003\n",
      "Epoch: 100\n",
      "Loss: 0.19469185627068328\n",
      "Epoch: 100\n",
      "Loss: 0.19443829548965003\n",
      "Epoch: 100\n",
      "Loss: 1.6331084498424653\n",
      "Epoch: 100\n",
      "Loss: 0.19419480919222215\n",
      "Epoch: 100\n",
      "Loss: 0.19443829548965003\n",
      "Epoch: 100\n",
      "Loss: 0.19419480919222215\n",
      "Epoch: 100\n",
      "Loss: 1.633048606843797\n",
      "Epoch: 100\n",
      "Loss: 0.19396070211304967\n",
      "Epoch: 100\n",
      "Loss: 0.19419480919222215\n",
      "Epoch: 100\n",
      "Loss: 0.19396070211304967\n",
      "Epoch: 100\n",
      "Loss: 1.633941960561943\n",
      "Epoch: 100\n",
      "Loss: 0.19373534805417925\n",
      "Epoch: 100\n",
      "Loss: 0.19396070211304967\n",
      "Epoch: 100\n",
      "Loss: 0.19373534805417925\n",
      "Epoch: 100\n",
      "Loss: 1.6355671559751306\n",
      "Epoch: 100\n",
      "Loss: 0.19351818128221138\n",
      "Epoch: 100\n",
      "Loss: 0.19373534805417925\n",
      "Epoch: 100\n",
      "Loss: 0.19351818128221138\n",
      "Epoch: 100\n",
      "Loss: 1.6331106555753088\n",
      "Epoch: 100\n",
      "Loss: 0.19330868917316554\n",
      "Epoch: 100\n",
      "Loss: 0.19351818128221138\n",
      "Epoch: 100\n",
      "Loss: 0.19330868917316554\n",
      "Epoch: 100\n",
      "Loss: 1.6320979989041635\n",
      "Epoch: 100\n",
      "Loss: 0.19330868917316554\n",
      "Epoch: 100\n",
      "Loss: 0.1931064058996523\n",
      "Epoch: 100\n",
      "Loss: 0.1931064058996523\n",
      "Epoch: 100\n",
      "Loss: 1.6339346574836815\n",
      "Epoch: 100\n",
      "Loss: 0.1931064058996523\n",
      "Epoch: 100\n",
      "Loss: 0.19291090699317542\n",
      "Epoch: 100\n",
      "Loss: 0.19291090699317542\n",
      "Epoch: 100\n",
      "Loss: 1.633754578124228\n",
      "Epoch: 100\n",
      "Loss: 0.19291090699317542\n",
      "Epoch: 100\n",
      "Loss: 0.19272180464448682\n",
      "Epoch: 100\n",
      "Loss: 0.19272180464448682\n",
      "Epoch: 100\n",
      "Loss: 0.19272180464448682\n",
      "Epoch: 100\n",
      "Loss: 1.634203436660009\n",
      "Epoch: 100\n",
      "Loss: 0.1925387436288515\n",
      "Epoch: 100\n",
      "Loss: 0.1925387436288515\n",
      "Epoch: 100\n",
      "Loss: 0.1925387436288515\n",
      "Epoch: 100\n",
      "Loss: 1.6313076520881018\n",
      "Epoch: 100\n",
      "Loss: 0.19236139776267616\n",
      "Epoch: 100\n",
      "Loss: 0.19236139776267616\n",
      "Epoch: 100\n",
      "Loss: 0.19236139776267616\n",
      "Epoch: 100\n",
      "Loss: 0.19218946681351465\n",
      "Epoch: 100\n",
      "Loss: 1.6328933482771948\n",
      "Epoch: 100\n",
      "Loss: 0.19218946681351465\n",
      "Epoch: 100\n",
      "Loss: 0.19218946681351465\n",
      "Epoch: 100\n",
      "Loss: 0.19202267379805496\n",
      "Epoch: 100\n",
      "Loss: 1.6328480563078327\n",
      "Epoch: 100\n",
      "Loss: 0.19202267379805496\n",
      "Epoch: 100\n",
      "Loss: 0.19202267379805496\n",
      "Epoch: 100\n",
      "Loss: 0.19186076261335228\n",
      "Epoch: 100\n",
      "Loss: 1.6337394892189834\n",
      "Epoch: 100\n",
      "Loss: 0.19186076261335228\n",
      "Epoch: 100\n",
      "Loss: 0.19170349595501512\n",
      "Epoch: 100\n",
      "Loss: 0.19186076261335228\n",
      "Epoch: 100\n",
      "Loss: 1.6329881633915702\n",
      "Epoch: 100\n",
      "Loss: 0.19170349595501512\n",
      "Epoch: 100\n",
      "Loss: 0.19170349595501512\n",
      "Epoch: 100\n",
      "Loss: 0.1915506534829785\n",
      "Epoch: 100\n",
      "Loss: 1.6331717690257734\n",
      "Epoch: 100\n",
      "Loss: 0.1915506534829785\n",
      "Epoch: 100\n",
      "Loss: 0.1915506534829785\n",
      "Epoch: 100\n",
      "Loss: 0.19140203020185667\n",
      "Epoch: 100\n",
      "Loss: 1.6346001799874263\n",
      "Epoch: 100\n",
      "Loss: 0.19140203020185667\n",
      "Epoch: 100\n",
      "Loss: 0.19140203020185667\n",
      "Epoch: 100\n",
      "Loss: 0.19125743502717812\n",
      "Epoch: 100\n",
      "Loss: 1.633414993556617\n",
      "Epoch: 100\n",
      "Loss: 0.19125743502717812\n",
      "Epoch: 100\n",
      "Loss: 0.19125743502717812\n",
      "Epoch: 100\n",
      "Loss: 0.19111668951353195\n",
      "Epoch: 100\n",
      "Loss: 1.6320552872239\n",
      "Epoch: 100\n",
      "Loss: 0.19111668951353195\n",
      "Epoch: 100\n",
      "Loss: 0.19097962672377125\n",
      "Epoch: 100\n",
      "Loss: 0.19111668951353195\n",
      "Epoch: 100\n",
      "Loss: 0.19097962672377125\n",
      "Epoch: 100\n",
      "Loss: 1.6324446263992083\n",
      "Epoch: 100\n",
      "Loss: 0.19084609022153456\n",
      "Epoch: 100\n",
      "Loss: 0.19097962672377125\n",
      "Epoch: 100\n",
      "Loss: 0.19084609022153456\n",
      "Epoch: 100\n",
      "Loss: 1.6336165017085928\n",
      "Epoch: 100\n",
      "Loss: 0.19071593317180383\n",
      "Epoch: 100\n",
      "Loss: 0.19084609022153456\n",
      "Epoch: 100\n",
      "Loss: 0.19071593317180383\n",
      "Epoch: 100\n",
      "Loss: 1.6329351346367975\n",
      "Epoch: 100\n",
      "Loss: 0.19071593317180383\n",
      "Epoch: 100\n",
      "Loss: 0.1905890175363728\n",
      "Epoch: 100\n",
      "Loss: 0.1905890175363728\n",
      "Epoch: 100\n",
      "Loss: 1.6340984324880339\n",
      "Epoch: 100\n",
      "Loss: 0.1905890175363728\n",
      "Epoch: 100\n",
      "Loss: 0.19046521335278138\n",
      "Epoch: 100\n",
      "Loss: 0.19046521335278138\n",
      "Epoch: 100\n",
      "Loss: 1.6305381901585208\n",
      "Epoch: 100\n",
      "Loss: 0.19046521335278138\n",
      "Epoch: 100\n",
      "Loss: 0.19034439808708156\n",
      "Epoch: 100\n",
      "Loss: 0.19034439808708156\n",
      "Epoch: 100\n",
      "Loss: 1.6329565687121406\n",
      "Epoch: 100\n",
      "Loss: 0.19034439808708156\n",
      "Epoch: 100\n",
      "Loss: 0.19022645605163888\n",
      "Epoch: 100\n",
      "Loss: 0.19022645605163888\n",
      "Epoch: 100\n",
      "Loss: 1.6342820816440067\n",
      "Epoch: 100\n",
      "Loss: 0.19022645605163888\n",
      "Epoch: 100\n",
      "Loss: 0.19011127788087115\n",
      "Epoch: 100\n",
      "Loss: 0.19011127788087115\n",
      "Epoch: 100\n",
      "Loss: 1.634067906024256\n",
      "Epoch: 100\n",
      "Loss: 0.19011127788087115\n",
      "Epoch: 100\n",
      "Loss: 0.18999876005814142\n",
      "Epoch: 100\n",
      "Loss: 0.18999876005814142\n",
      "Epoch: 100\n",
      "Loss: 1.6328594926005586\n",
      "Epoch: 100\n",
      "Loss: 0.18999876005814142\n",
      "Epoch: 100\n",
      "Loss: 0.189888804488414\n",
      "Epoch: 100\n",
      "Loss: 0.189888804488414\n",
      "Epoch: 100\n",
      "Loss: 1.6313803797333757\n",
      "Epoch: 100\n",
      "Loss: 0.1897813181115032\n",
      "Epoch: 100\n",
      "Loss: 0.189888804488414\n",
      "Epoch: 100\n",
      "Loss: 0.1897813181115032\n",
      "Epoch: 100\n",
      "Loss: 1.6325536349133696\n",
      "Epoch: 100\n",
      "Loss: 0.1897813181115032\n",
      "Epoch: 100\n",
      "Loss: 0.18967621255165557\n",
      "Epoch: 100\n",
      "Loss: 0.18967621255165557\n",
      "Epoch: 100\n",
      "Loss: 1.6304184873403835\n",
      "Epoch: 100\n",
      "Loss: 0.18967621255165557\n",
      "Epoch: 100\n",
      "Loss: 0.18957340379947296\n",
      "Epoch: 100\n",
      "Loss: 0.18957340379947296\n",
      "Epoch: 100\n",
      "Loss: 1.6332622001899604\n",
      "Epoch: 100\n",
      "Loss: 0.18947281192290016\n",
      "Epoch: 100\n",
      "Loss: 0.18957340379947296\n",
      "Epoch: 100\n",
      "Loss: 0.18947281192290016\n",
      "Epoch: 100\n",
      "Loss: 1.6326444602260144\n",
      "Epoch: 100\n",
      "Loss: 0.18947281192290016\n",
      "Epoch: 100\n",
      "Loss: 0.18937436080405448\n",
      "Epoch: 100\n",
      "Loss: 0.18937436080405448\n",
      "Epoch: 100\n",
      "Loss: 1.6332815244338401\n",
      "Epoch: 100\n",
      "Loss: 0.18937436080405448\n",
      "Epoch: 100\n",
      "Loss: 0.1892779778992596\n",
      "Epoch: 100\n",
      "Loss: 0.1892779778992596\n",
      "Epoch: 100\n",
      "Loss: 1.633420642883646\n",
      "Epoch: 100\n",
      "Loss: 0.1892779778992596\n",
      "Epoch: 100\n",
      "Loss: 0.18918359401981494\n",
      "Epoch: 100\n",
      "Loss: 0.18918359401981494\n",
      "Epoch: 100\n",
      "Loss: 1.6339838359845467\n",
      "Epoch: 100\n",
      "Loss: 0.18909114313131317\n",
      "Epoch: 100\n",
      "Loss: 0.18918359401981494\n",
      "Epoch: 100\n",
      "Loss: 0.18909114313131317\n",
      "Epoch: 100\n",
      "Loss: 1.632054722268962\n",
      "Epoch: 100\n",
      "Loss: 0.18900056216954222\n",
      "Epoch: 100\n",
      "Loss: 0.18909114313131317\n",
      "Epoch: 100\n",
      "Loss: 0.18900056216954222\n",
      "Epoch: 100\n",
      "Loss: 0.18891179087122714\n",
      "Epoch: 100\n",
      "Loss: 0.18900056216954222\n",
      "Epoch: 100\n",
      "Loss: 1.6335192207052676\n",
      "Epoch: 100\n",
      "Loss: 0.18891179087122714\n",
      "Epoch: 100\n",
      "Loss: 0.18882477161801703\n",
      "Epoch: 100\n",
      "Loss: 0.18891179087122714\n",
      "Epoch: 100\n",
      "Loss: 1.6307841153702909\n",
      "Epoch: 100\n",
      "Loss: 0.18882477161801703\n",
      "Epoch: 100\n",
      "Loss: 0.18873944929227904\n",
      "Epoch: 100\n",
      "Loss: 0.18882477161801703\n",
      "Epoch: 100\n",
      "Loss: 1.6336099720700736\n",
      "Epoch: 100\n",
      "Loss: 0.18873944929227904\n",
      "Epoch: 100\n",
      "Loss: 0.18865577114353885\n",
      "Epoch: 100\n",
      "Loss: 0.18873944929227904\n",
      "Epoch: 100\n",
      "Loss: 1.6319890016851595\n",
      "Epoch: 100\n",
      "Loss: 0.18865577114353885\n",
      "Epoch: 100\n",
      "Loss: 0.18865577114353885\n",
      "Epoch: 100\n",
      "Loss: 0.18857368666429694\n",
      "Epoch: 100\n",
      "Loss: 0.18857368666429694\n",
      "Epoch: 100\n",
      "Loss: 1.6318758343633966\n",
      "Epoch: 100\n",
      "Loss: 0.18857368666429694\n",
      "Epoch: 100\n",
      "Loss: 0.18849314747441648\n",
      "Epoch: 100\n",
      "Loss: 0.18849314747441648\n",
      "Epoch: 100\n",
      "Loss: 1.6329112753313106\n",
      "Epoch: 100\n",
      "Loss: 0.18841410721301957\n",
      "Epoch: 100\n",
      "Loss: 0.18849314747441648\n",
      "Epoch: 100\n",
      "Loss: 0.18841410721301957\n",
      "Epoch: 100\n",
      "Loss: 1.63286051372767\n",
      "Epoch: 100\n",
      "Loss: 0.18841410721301957\n",
      "Epoch: 100\n",
      "Loss: 0.18833652143729118\n",
      "Epoch: 100\n",
      "Loss: 0.18833652143729118\n",
      "Epoch: 100\n",
      "Loss: 1.63297434822919\n",
      "Epoch: 100\n",
      "Loss: 0.18833652143729118\n",
      "Epoch: 100\n",
      "Loss: 0.18826034752742082\n",
      "Epoch: 100\n",
      "Loss: 0.18826034752742082\n",
      "Epoch: 100\n",
      "Loss: 1.6353081067508262\n",
      "Epoch: 100\n",
      "Loss: 0.18826034752742082\n",
      "Epoch: 100\n",
      "Loss: 0.18818554459717712\n",
      "Epoch: 100\n",
      "Loss: 0.18818554459717712\n",
      "Epoch: 100\n",
      "Loss: 1.6335814076378279\n",
      "Epoch: 100\n",
      "Loss: 0.18818554459717712\n",
      "Epoch: 100\n",
      "Loss: 0.18811207340948163\n",
      "Epoch: 100\n",
      "Loss: 0.18811207340948163\n",
      "Epoch: 100\n",
      "Loss: 1.632107682211211\n",
      "Epoch: 100\n",
      "Loss: 0.18811207340948163\n",
      "Epoch: 100\n",
      "Loss: 0.1880398962967515\n",
      "Epoch: 100\n",
      "Loss: 0.1880398962967515\n",
      "Epoch: 100\n",
      "Loss: 1.6314645963037526\n",
      "Epoch: 100\n",
      "Loss: 0.1880398962967515\n",
      "Epoch: 100\n",
      "Loss: 0.18796897708544266\n",
      "Epoch: 100\n",
      "Loss: 0.18796897708544266\n",
      "Epoch: 100\n",
      "Loss: 1.634204380327656\n",
      "Epoch: 100\n",
      "Loss: 0.18796897708544266\n",
      "Epoch: 100\n",
      "Loss: 0.18789928102460995\n",
      "Epoch: 100\n",
      "Loss: 0.18789928102460995\n",
      "Epoch: 100\n",
      "Loss: 1.6330515320085266\n",
      "Epoch: 100\n",
      "Loss: 0.18789928102460995\n",
      "Epoch: 100\n",
      "Loss: 0.1878307747181378\n",
      "Epoch: 100\n",
      "Loss: 0.1878307747181378\n",
      "Epoch: 100\n",
      "Loss: 1.629599099844307\n",
      "Epoch: 100\n",
      "Loss: 0.1878307747181378\n",
      "Epoch: 100\n",
      "Loss: 0.18776342606034904\n",
      "Epoch: 100\n",
      "Loss: 0.18776342606034904\n",
      "Epoch: 100\n",
      "Loss: 1.630164077139561\n",
      "Epoch: 100\n",
      "Loss: 0.18776342606034904\n",
      "Epoch: 100\n",
      "Loss: 0.18769720417496516\n",
      "Epoch: 100\n",
      "Loss: 0.18769720417496516\n",
      "Epoch: 100\n",
      "Loss: 1.633366709412149\n",
      "Epoch: 100\n",
      "Loss: 0.18769720417496516\n",
      "Epoch: 100\n",
      "Loss: 0.18763207935700782\n",
      "Epoch: 100\n",
      "Loss: 0.18763207935700782\n",
      "Epoch: 100\n",
      "Loss: 1.6334595865165773\n",
      "Epoch: 100\n",
      "Loss: 0.18763207935700782\n",
      "Epoch: 100\n",
      "Loss: 0.1875680230176483\n",
      "Epoch: 100\n",
      "Loss: 0.1875680230176483\n",
      "Epoch: 100\n",
      "Loss: 1.6350945540379358\n",
      "Epoch: 100\n",
      "Loss: 0.1875680230176483\n",
      "Epoch: 100\n",
      "Loss: 0.1875050076317569\n",
      "Epoch: 100\n",
      "Loss: 0.1875050076317569\n",
      "Epoch: 100\n",
      "Loss: 1.6310155935805288\n",
      "Epoch: 100\n",
      "Loss: 0.1875050076317569\n",
      "Epoch: 100\n",
      "Loss: 0.18744300668805317\n",
      "Epoch: 100\n",
      "Loss: 0.18744300668805317\n",
      "Epoch: 100\n",
      "Loss: 1.6314704805655522\n",
      "Epoch: 100\n",
      "Loss: 0.18744300668805317\n",
      "Epoch: 100\n",
      "Loss: 0.18738199464179892\n",
      "Epoch: 100\n",
      "Loss: 0.18738199464179892\n",
      "Epoch: 100\n",
      "Loss: 1.6326465143336781\n",
      "Epoch: 100\n",
      "Loss: 0.18738199464179892\n",
      "Epoch: 100\n",
      "Loss: 0.1873219468697596\n",
      "Epoch: 100\n",
      "Loss: 0.1873219468697596\n",
      "Epoch: 100\n",
      "Loss: 1.634596906244185\n",
      "Epoch: 100\n",
      "Loss: 0.1873219468697596\n",
      "Epoch: 100\n",
      "Loss: 0.18726283962748028\n",
      "Epoch: 100\n",
      "Loss: 0.18726283962748028\n",
      "Epoch: 100\n",
      "Loss: 1.6308466444185286\n",
      "Epoch: 100\n",
      "Loss: 0.18726283962748028\n",
      "Epoch: 100\n",
      "Loss: 0.1872046500087385\n",
      "Epoch: 100\n",
      "Loss: 0.1872046500087385\n",
      "Epoch: 100\n",
      "Loss: 0.1872046500087385\n",
      "Epoch: 100\n",
      "Loss: 1.6310211200537632\n",
      "Epoch: 100\n",
      "Loss: 0.1871473559069822\n",
      "Epoch: 100\n",
      "Loss: 0.1871473559069822\n",
      "Epoch: 100\n",
      "Loss: 0.1871473559069822\n",
      "Epoch: 100\n",
      "Loss: 1.6317757137891653\n",
      "Epoch: 100\n",
      "Loss: 0.1870909359788384\n",
      "Epoch: 100\n",
      "Loss: 0.1870909359788384\n",
      "Epoch: 100\n",
      "Loss: 0.1870909359788384\n",
      "Epoch: 100\n",
      "Loss: 0.18703536960934136\n",
      "Epoch: 100\n",
      "Loss: 1.6329147447616374\n",
      "Epoch: 100\n",
      "Loss: 0.18703536960934136\n",
      "Epoch: 100\n",
      "Loss: 0.18703536960934136\n",
      "Epoch: 100\n",
      "Loss: 0.18698063687914698\n",
      "Loss: 1.6293327574852523\n",
      "Epoch: 100\n",
      "Loss: 0.18698063687914698\n",
      "Loss: 0.18698063687914698\n",
      "Loss: 1.6322717822355466\n",
      "Epoch: 100\n",
      "Loss: 1.63445987790043\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 100\n",
      "Loss: 1.6332087497902603\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 100\n",
      "Loss: 0.37950671970632377\n",
      "Epoch: 100\n",
      "Loss: 1.6308496490594555\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 100\n",
      "Loss: 0.37950671970632377\n",
      "Epoch: 100\n",
      "Loss: 0.25611202584798515\n",
      "Epoch: 100\n",
      "Loss: 1.6307414364038681\n",
      "Loss: 1.0000576934337357\n",
      "Epoch: 100\n",
      "Loss: 0.25611202584798515\n",
      "Epoch: 100\n",
      "Loss: 0.23698305197050004\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.2275583712099578\n",
      "Epoch: 100\n",
      "Loss: 0.23698305197050004\n",
      "Epoch: 100\n",
      "Loss: 0.22166524219084863\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 100\n",
      "Loss: 0.2275583712099578\n",
      "Epoch: 100\n",
      "Loss: 0.21752659543164224\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1.0000576934337357\n",
      "Epoch: 100\n",
      "Loss: 0.22166524219084863\n",
      "Epoch: 100\n",
      "Loss: 0.21441094043957018\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.21752659543164224\n",
      "Epoch: 100\n",
      "Loss: 0.21195434576024869\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.2099522409674381\n",
      "Epoch: 100\n",
      "Loss: 0.21441094043957018\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.2082792992699609\n",
      "Epoch: 100\n",
      "Loss: 0.21195434576024869\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.206853714597935\n",
      "Epoch: 100\n",
      "Loss: 0.2099522409674381\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20561945724300087\n",
      "Epoch: 100\n",
      "Loss: 0.2082792992699609\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20453668710729525\n",
      "Epoch: 100\n",
      "Loss: 0.206853714597935\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20357621328339626\n",
      "Epoch: 100\n",
      "Loss: 0.20561945724300087\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20271611243067378\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20453668710729525\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20193957145754804\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20357621328339626\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.2012334610726017\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20271611243067378\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20058736458634327\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.20193957145754804\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19999290033892086\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.2012334610726017\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1994432390020462\n",
      "Epoch: 100\n",
      "Loss: 0.20058736458634327\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19893275332755705\n",
      "Epoch: 100\n",
      "Loss: 0.19999290033892086\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19845675975202623\n",
      "Epoch: 100\n",
      "Loss: 0.1994432390020462\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19801132484170425\n",
      "Epoch: 100\n",
      "Loss: 0.19893275332755705\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.197593118241385\n",
      "Epoch: 100\n",
      "Loss: 0.19845675975202623\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19719929947240541\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19801132484170425\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19682742971464104\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.197593118241385\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19647540227584065\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19719929947240541\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19614138721532884\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19682742971464104\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19582378681642876\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19647540227584065\n",
      "Epoch: 100\n",
      "Loss: 0.1955211994665458\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19614138721532884\n",
      "Epoch: 100\n",
      "Loss: 0.1952323901209335\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19582378681642876\n",
      "Epoch: 100\n",
      "Loss: 0.1949562659719045\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1955211994665458\n",
      "Epoch: 100\n",
      "Loss: 0.19469185627068328\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19443829548965003\n",
      "Epoch: 100\n",
      "Loss: 0.1952323901209335\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1949562659719045\n",
      "Epoch: 100\n",
      "Loss: 0.19419480919222215\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19469185627068328\n",
      "Epoch: 100\n",
      "Loss: 0.19396070211304967\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19373534805417925\n",
      "Epoch: 100\n",
      "Loss: 0.19443829548965003\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19419480919222215\n",
      "Epoch: 100\n",
      "Loss: 0.19351818128221138\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19396070211304967\n",
      "Epoch: 100\n",
      "Loss: 0.19330868917316554\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1931064058996523\n",
      "Epoch: 100\n",
      "Loss: 0.19373534805417925\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19291090699317542\n",
      "Epoch: 100\n",
      "Loss: 0.19351818128221138\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19272180464448682\n",
      "Epoch: 100\n",
      "Loss: 0.19330868917316554\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1925387436288515\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1931064058996523\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19236139776267616\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19291090699317542\n",
      "Epoch: 100\n",
      "Loss: 0.19218946681351465\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19272180464448682\n",
      "Epoch: 100\n",
      "Loss: 0.19202267379805496\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1925387436288515\n",
      "Epoch: 100\n",
      "Loss: 0.19186076261335228\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19236139776267616\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19170349595501512\n",
      "Epoch: 100\n",
      "Loss: 0.19218946681351465\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1915506534829785\n",
      "Epoch: 100\n",
      "Loss: 0.19202267379805496\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19140203020185667\n",
      "Epoch: 100\n",
      "Loss: 0.19186076261335228\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19125743502717812\n",
      "Epoch: 100\n",
      "Loss: 0.19170349595501512\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19111668951353195\n",
      "Epoch: 100\n",
      "Loss: 0.1915506534829785\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19097962672377125\n",
      "Epoch: 100\n",
      "Loss: 0.19140203020185667\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19084609022153456\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19125743502717812\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19071593317180383\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19111668951353195\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1905890175363728\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19097962672377125\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19046521335278138\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19084609022153456\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19034439808708156\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19071593317180383\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19022645605163888\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1905890175363728\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19011127788087115\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.19046521335278138\n",
      "Epoch: 100\n",
      "Loss: 0.18999876005814142\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.189888804488414\n",
      "Epoch: 100\n",
      "Loss: 0.19034439808708156\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1897813181115032\n",
      "Epoch: 100\n",
      "Loss: 0.19022645605163888\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18967621255165557\n",
      "Epoch: 100\n",
      "Loss: 0.19011127788087115\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18957340379947296\n",
      "Epoch: 100\n",
      "Loss: 0.18999876005814142\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18947281192290016\n",
      "Epoch: 100\n",
      "Loss: 0.189888804488414\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18937436080405448\n",
      "Epoch: 100\n",
      "Loss: 0.1897813181115032\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1892779778992596\n",
      "Epoch: 100\n",
      "Loss: 0.18967621255165557\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18918359401981494\n",
      "Epoch: 100\n",
      "Loss: 0.18957340379947296\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18909114313131317\n",
      "Epoch: 100\n",
      "Loss: 0.18947281192290016\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18900056216954222\n",
      "Epoch: 100\n",
      "Loss: 0.18937436080405448\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18891179087122714\n",
      "Epoch: 100\n",
      "Loss: 0.1892779778992596\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18918359401981494\n",
      "Epoch: 100\n",
      "Loss: 0.18882477161801703\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18909114313131317\n",
      "Epoch: 100\n",
      "Loss: 0.18873944929227904\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18900056216954222\n",
      "Epoch: 100\n",
      "Loss: 0.18865577114353885\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18891179087122714\n",
      "Epoch: 100\n",
      "Loss: 0.18857368666429694\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18882477161801703\n",
      "Epoch: 100\n",
      "Loss: 0.18849314747441648\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18873944929227904\n",
      "Epoch: 100\n",
      "Loss: 0.18841410721301957\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18865577114353885\n",
      "Epoch: 100\n",
      "Loss: 0.18833652143729118\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18826034752742082\n",
      "Epoch: 100\n",
      "Loss: 0.18857368666429694\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18818554459717712\n",
      "Epoch: 100\n",
      "Loss: 0.18849314747441648\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18811207340948163\n",
      "Epoch: 100\n",
      "Loss: 0.18841410721301957\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1880398962967515\n",
      "Epoch: 100\n",
      "Loss: 0.18833652143729118\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18796897708544266\n",
      "Epoch: 100\n",
      "Loss: 0.18826034752742082\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18789928102460995\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18818554459717712\n",
      "Epoch: 100\n",
      "Loss: 0.1878307747181378\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18811207340948163\n",
      "Epoch: 100\n",
      "Loss: 0.18776342606034904\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1880398962967515\n",
      "Epoch: 100\n",
      "Loss: 0.18769720417496516\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18763207935700782\n",
      "Epoch: 100\n",
      "Loss: 0.18796897708544266\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1875680230176483\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18789928102460995\n",
      "Epoch: 100\n",
      "Loss: 0.1875050076317569\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1878307747181378\n",
      "Epoch: 100\n",
      "Loss: 0.18744300668805317\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18738199464179892\n",
      "Epoch: 100\n",
      "Loss: 0.18776342606034904\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1873219468697596\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18769720417496516\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18726283962748028\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18763207935700782\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1872046500087385\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1875680230176483\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1871473559069822\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1875050076317569\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.1870909359788384\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18744300668805317\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18703536960934136\n",
      "Epoch: 100\n",
      "Loss: 0.18738199464179892\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18698063687914698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at src/gen/challenge/nn_challenge.rs:29:10:\n",
      "called `Result::unwrap()` on an `Err` value: \"Invalid neural network shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 196, output_size: 168 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 168, output_size: 196 }, activation: ReLU }] }\"\n",
      "stack backtrace:\n",
      "   0: rust_begin_unwind\n",
      "   1: core::panicking::panic_fmt\n",
      "   2: core::result::unwrap_failed\n",
      "   3: <learn::gen::challenge::nn_challenge::NeuralNetworkChallenge as learn::evol::evolution::challenge::Challenge<learn::gen::pheno::nn_pheno::NeuralNetworkPhenotype>>::score\n",
      "   4: core::ops::function::impls::<impl core::ops::function::FnMut<A> for &F>::call_mut\n",
      "   5: rayon_core::join::join_context::{{closure}}\n",
      "   6: rayon::iter::plumbing::bridge_producer_consumer::helper\n",
      "   7: rayon_core::job::StackJob<L,F,R>::run_inline\n",
      "   8: rayon_core::join::join_context::{{closure}}\n",
      "   9: rayon::iter::plumbing::bridge_producer_consumer::helper\n",
      "  10: <rayon_core::job::StackJob<L,F,R> as rayon_core::job::Job>::execute\n",
      "  11: rayon_core::registry::WorkerThread::wait_until_cold\n",
      "  12: rayon_core::join::join_context::{{closure}}\n",
      "  13: rayon_core::join::join_context::{{closure}}\n",
      "  14: rayon::iter::plumbing::bridge_producer_consumer::helper\n",
      "  15: rayon_core::join::join_context::{{closure}}\n",
      "  16: <rayon_core::job::StackJob<L,F,R> as rayon_core::job::Job>::execute\n",
      "  17: rayon_core::registry::WorkerThread::wait_until_cold\n",
      "  18: rayon_core::registry::ThreadBuilder::run\n",
      "note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1873219468697596\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 0.18726283962748028\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Loss: 0.1872046500087385\n",
      "Epoch: 100\n",
      "Loss: 1\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Tanh }] }\n",
      "Epoch: 100\n",
      "Loss: 0.1871473559069822\n",
      "Epoch: 100\n",
      "Loss: 1.6913241645323618\n",
      "Epoch: 100\n",
      "Loss: 0.1870909359788384\n",
      "Epoch: 100\n",
      "Loss: 1.659660677832816\n",
      "Epoch: 100\n",
      "Loss: 0.18703536960934136\n",
      "Epoch: 100\n",
      "Loss: 1.6513927514272417\n",
      "Epoch: 100\n",
      "Loss: 0.18698063687914698\n",
      "Loss: 1.6456738405104643\n",
      "Epoch: 100\n",
      "Loss: 1.6414422867767064\n",
      "Epoch: 100\n",
      "Loss: 1.6404925358575446\n",
      "Epoch: 100\n",
      "Loss: 1.639083367230673\n",
      "Epoch: 100\n",
      "Loss: 1.6402130790702258\n",
      "Epoch: 100\n",
      "Loss: 1.6363079813218153\n",
      "Epoch: 100\n",
      "Loss: 1.6373136080337027\n",
      "Epoch: 100\n",
      "Loss: 1.6388917812900259\n",
      "Epoch: 100\n",
      "Loss: 1.6328715741630146\n",
      "Epoch: 100\n",
      "Loss: 1.6352756970090339\n",
      "Epoch: 100\n",
      "Loss: 1.635074273120222\n",
      "Epoch: 100\n",
      "Loss: 1.6351367149133673\n",
      "Epoch: 100\n",
      "Loss: 1.6364987457450353\n",
      "Epoch: 100\n",
      "Loss: 1.6330457142550494\n",
      "Epoch: 100\n",
      "Loss: 1.635652113133762\n",
      "Epoch: 100\n",
      "Loss: 1.6344600494030825\n",
      "Epoch: 100\n",
      "Loss: 1.6350929824853901\n",
      "Epoch: 100\n",
      "Loss: 1.63317564708029\n",
      "Epoch: 100\n",
      "Loss: 1.6342663745199677\n",
      "Epoch: 100\n",
      "Loss: 1.6333634597004265\n",
      "Epoch: 100\n",
      "Loss: 1.635881289297886\n",
      "Epoch: 100\n",
      "Loss: 1.6336179363138719\n",
      "Epoch: 100\n",
      "Loss: 1.633107869908832\n",
      "Epoch: 100\n",
      "Loss: 1.635128327628914\n",
      "Epoch: 100\n",
      "Loss: 1.635009184844702\n",
      "Epoch: 100\n",
      "Loss: 1.634116273313654\n",
      "Epoch: 100\n",
      "Loss: 1.6350924447497115\n",
      "Epoch: 100\n",
      "Loss: 1.6324933811897189\n",
      "Epoch: 100\n",
      "Loss: 1.6331084498424653\n",
      "Epoch: 100\n",
      "Loss: 1.633048606843797\n",
      "Epoch: 100\n",
      "Loss: 1.633941960561943\n",
      "Epoch: 100\n",
      "Loss: 1.6355671559751306\n",
      "Epoch: 100\n",
      "Loss: 1.6331106555753088\n",
      "Epoch: 100\n",
      "Loss: 1.6320979989041635\n",
      "Epoch: 100\n",
      "Loss: 1.6339346574836815\n",
      "Epoch: 100\n",
      "Loss: 1.633754578124228\n",
      "Epoch: 100\n",
      "Loss: 1.634203436660009\n",
      "Epoch: 100\n",
      "Loss: 1.6313076520881018\n",
      "Epoch: 100\n",
      "Loss: 1.6328933482771948\n",
      "Epoch: 100\n",
      "Loss: 1.6328480563078327\n",
      "Epoch: 100\n",
      "Loss: 1.6337394892189834\n",
      "Epoch: 100\n",
      "Loss: 1.6329881633915702\n",
      "Epoch: 100\n",
      "Loss: 1.6331717690257734\n",
      "Epoch: 100\n",
      "Loss: 1.6346001799874263\n",
      "Epoch: 100\n",
      "Loss: 1.633414993556617\n",
      "Epoch: 100\n",
      "Loss: 1.6320552872239\n",
      "Epoch: 100\n",
      "Loss: 1.6324446263992083\n",
      "Epoch: 100\n",
      "Loss: 1.6336165017085928\n",
      "Epoch: 100\n",
      "Loss: 1.6329351346367975\n",
      "Epoch: 100\n",
      "Loss: 1.6340984324880339\n",
      "Epoch: 100\n",
      "Loss: 1.6305381901585208\n",
      "Epoch: 100\n",
      "Loss: 1.6329565687121406\n",
      "Epoch: 100\n",
      "Loss: 1.6342820816440067\n",
      "Epoch: 100\n",
      "Loss: 1.634067906024256\n",
      "Epoch: 100\n",
      "Loss: 1.6328594926005586\n",
      "Epoch: 100\n",
      "Loss: 1.6313803797333757\n",
      "Epoch: 100\n",
      "Loss: 1.6325536349133696\n",
      "Epoch: 100\n",
      "Loss: 1.6304184873403835\n",
      "Epoch: 100\n",
      "Loss: 1.6332622001899604\n",
      "Epoch: 100\n",
      "Loss: 1.6326444602260144\n",
      "Epoch: 100\n",
      "Loss: 1.6332815244338401\n",
      "Epoch: 100\n",
      "Loss: 1.633420642883646\n",
      "Epoch: 100\n",
      "Loss: 1.6339838359845467\n",
      "Epoch: 100\n",
      "Loss: 1.632054722268962\n",
      "Epoch: 100\n",
      "Loss: 1.6335192207052676\n",
      "Epoch: 100\n",
      "Loss: 1.6307841153702909\n",
      "Epoch: 100\n",
      "Loss: 1.6336099720700736\n",
      "Epoch: 100\n",
      "Loss: 1.6319890016851595\n",
      "Epoch: 100\n",
      "Loss: 1.6318758343633966\n",
      "Epoch: 100\n",
      "Loss: 1.6329112753313106\n",
      "Epoch: 100\n",
      "Loss: 1.63286051372767\n",
      "Epoch: 100\n",
      "Loss: 1.63297434822919\n",
      "Epoch: 100\n",
      "Loss: 1.6353081067508262\n",
      "Epoch: 100\n",
      "Loss: 1.6335814076378279\n",
      "Epoch: 100\n",
      "Loss: 1.632107682211211\n",
      "Epoch: 100\n",
      "Loss: 1.6314645963037526\n",
      "Epoch: 100\n",
      "Loss: 1.634204380327656\n",
      "Epoch: 100\n",
      "Loss: 1.6330515320085266\n",
      "Epoch: 100\n",
      "Loss: 1.629599099844307\n",
      "Epoch: 100\n",
      "Loss: 1.630164077139561\n",
      "Epoch: 100\n",
      "Loss: 1.633366709412149\n",
      "Epoch: 100\n",
      "Loss: 1.6334595865165773\n",
      "Epoch: 100\n",
      "Loss: 1.6350945540379358\n",
      "Epoch: 100\n",
      "Loss: 1.6310155935805288\n",
      "Epoch: 100\n",
      "Loss: 1.6314704805655522\n",
      "Epoch: 100\n",
      "Loss: 1.6326465143336781\n",
      "Epoch: 100\n",
      "Loss: 1.634596906244185\n",
      "Epoch: 100\n",
      "Loss: 1.6308466444185286\n",
      "Epoch: 100\n",
      "Loss: 1.6310211200537632\n",
      "Epoch: 100\n",
      "Loss: 1.6317757137891653\n",
      "Epoch: 100\n",
      "Loss: 1.6329147447616374\n",
      "Epoch: 100\n",
      "Loss: 1.6293327574852523\n",
      "Epoch: 100\n",
      "Loss: 1.6322717822355466\n",
      "Epoch: 100\n",
      "Loss: 1.63445987790043\n",
      "Epoch: 100\n",
      "Loss: 1.6332087497902603\n",
      "Epoch: 100\n",
      "Loss: 1.6308496490594555\n",
      "Epoch: 100\n",
      "Loss: 1.6307414364038681\n",
      "Error occurred during model training: Command '['./nn_generator', '--model-directory', './trained_model', '--input-file', 'input.csv', '--target-file', 'target.csv', '--training-verification-ratio', '0.7', '--learning-rate', '0.01', '--epochs', '100', '--tolerance', '0.1', '--num-generations', '100', '--log-level', '1', '--population-size', '4', '--num-offsprings', '10']' returned non-zero exit status 101.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define parameters for `nn_generator`\n",
    "model_directory = \"./trained_model\"\n",
    "# create the trained model directory\n",
    "import os\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "input_file = \"input.csv\"\n",
    "target_file = \"target.csv\"\n",
    "training_verification_ratio = 0.7\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "tolerance = 0.1\n",
    "num_generations = 100\n",
    "log_level = 1\n",
    "population_size = 4\n",
    "num_offsprings = 10\n",
    "\n",
    "# Create the command for training the neural network\n",
    "command = [\n",
    "    \"./nn_generator\",\n",
    "    \"--model-directory\", model_directory,\n",
    "    \"--input-file\", input_file,\n",
    "    \"--target-file\", target_file,\n",
    "    \"--training-verification-ratio\", str(training_verification_ratio),\n",
    "    \"--learning-rate\", str(learning_rate),\n",
    "    \"--epochs\", str(epochs),\n",
    "    \"--tolerance\", str(tolerance),\n",
    "    \"--num-generations\", str(num_generations),\n",
    "    \"--log-level\", str(log_level),\n",
    "    \"--population-size\", str(population_size),\n",
    "    \"--num-offsprings\", str(num_offsprings)\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "try:\n",
    "    #subprocess.run(command, check=True)\n",
    "    # Create a copy of the current environment variables and add RUST_BACKTRACE=1\n",
    "    env = os.environ.copy()\n",
    "    env[\"RUST_BACKTRACE\"] = \"1\"\n",
    "\n",
    "    # Run the command\n",
    "    subprocess.run(command, check=True, env=env)\n",
    "    print(\"Model training completed successfully and saved in:\", model_directory)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error occurred during model training:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827f8e5",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5477d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x_test_flat, y_test_onehot)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(x_test_flat, y_test_onehot)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
