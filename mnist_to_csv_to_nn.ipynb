{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5baa1a4e",
   "metadata": {},
   "source": [
    "# MNIST Dataset Processing and Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a41b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:38:33.185467: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-07 10:38:33.189243: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-07 10:38:33.200164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733567913.220071    1063 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733567913.225277    1063 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 10:38:33.247494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7a49b",
   "metadata": {},
   "source": [
    "## Step 1: Download and Process MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a423b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Resize images to 16x16 (256 pixels)\n",
    "x_train = x_train[:, ::2, ::2]  # Downsample by skipping every other pixel\n",
    "x_test = x_test[:, ::2, ::2]\n",
    "\n",
    "# Normalize pixel values to range [0.0, 1.0] (0.0 for white, 1.0 for black)\n",
    "x_train = 1 - x_train / 255.0\n",
    "x_test = 1 - x_test / 255.0\n",
    "\n",
    "# Flatten images into 256-pixel vectors\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Convert targets to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed3dd7",
   "metadata": {},
   "source": [
    "## Step 2: Save Processed Data to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefa21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input.csv and target.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save input data to input.csv\n",
    "input_df = pd.DataFrame(x_train_flat)\n",
    "input_df.to_csv(\"input.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "# Save target data to target.csv\n",
    "target_df = pd.DataFrame(y_train_onehot)\n",
    "target_df.to_csv(\"target.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Saved input.csv and target.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708ac4e",
   "metadata": {},
   "source": [
    "## Step 3: Create a Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ddb6f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 10, output_size: 474 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 474, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 10, output_size: 750 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 750, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 0\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Epoch 0: Loss 1.0000062181886489\n",
      "Epoch: 1\n",
      "Epoch 0: Loss 0.37627824181987113\n",
      "Epoch: 1\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 1: Loss 0.2558121816986619\n",
      "Epoch: 2\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 2: Loss 0.23680511798870263\n",
      "Epoch: 3\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Epoch 3: Loss 0.2274112347652274\n",
      "Epoch: 4\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 4: Loss 0.22153702362531902\n",
      "Epoch: 5\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 5: Loss 0.21741384423537802\n",
      "Epoch: 6\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 6: Loss 0.21431130289438044\n",
      "Epoch: 7\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 7: Loss 0.2118658439847008\n",
      "Epoch: 8\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 0: Loss 0.9999975858079552\n",
      "Epoch: 1\n",
      "Epoch 8: Loss 0.20987323807868669\n",
      "Epoch: 9\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 9: Loss 0.20820846858864328\n",
      "Epoch: 10\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 10: Loss 0.2067899838995135\n",
      "Epoch: 11\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 11: Loss 0.205561952495719\n",
      "Epoch: 12\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 0: Loss 1.0000953899960197\n",
      "Epoch: 1\n",
      "Epoch 12: Loss 0.20448468597977243\n",
      "Epoch: 13\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 13: Loss 0.2035291093733321\n",
      "Epoch: 14\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 14: Loss 0.20267338851076805\n",
      "Epoch: 15\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 15: Loss 0.20190077983011573\n",
      "Epoch: 16\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 16: Loss 0.2011982093871973\n",
      "Epoch: 17\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 17: Loss 0.2005553057310508\n",
      "Epoch: 18\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 18: Loss 0.19996372524706993\n",
      "Epoch: 19\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 19: Loss 0.19941667144875314\n",
      "Epoch: 20\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 20: Loss 0.1989085460194826\n",
      "Epoch: 21\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 21: Loss 0.19843469122183763\n",
      "Epoch: 22\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 22: Loss 0.1979911968306329\n",
      "Epoch: 23\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 23: Loss 0.1975747533834638\n",
      "Epoch: 24\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 24: Loss 0.19718253918241865\n",
      "Epoch: 25\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 25: Loss 0.1968121322363012\n",
      "Epoch: 26\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 26: Loss 0.19646144087539713\n",
      "Epoch: 27\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 27: Loss 0.19612864851832398\n",
      "Epoch: 28\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 28: Loss 0.19581216928839298\n",
      "Epoch: 29\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 29: Loss 0.19551061203712966\n",
      "Epoch: 30\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 30: Loss 0.19522275094831093\n",
      "Epoch: 31\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 31: Loss 0.1949475013414413\n",
      "Epoch: 32\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 32: Loss 0.19468389961965335\n",
      "Epoch: 33\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 33: Loss 0.19443108654858512\n",
      "Epoch: 34\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 34: Loss 0.1941882932325708\n",
      "Epoch: 35\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 35: Loss 0.19395482929061955\n",
      "Epoch: 36\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 36: Loss 0.1937300728382328\n",
      "Epoch: 37\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 37: Loss 0.19351346196038938\n",
      "Epoch: 38\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 38: Loss 0.19330448742303805\n",
      "Epoch: 39\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 39: Loss 0.19310268641854766\n",
      "Epoch: 40\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 40: Loss 0.19290763717853837\n",
      "Epoch: 41\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 41: Loss 0.19271895431785277\n",
      "Epoch: 42\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 42: Loss 0.1925362847972406\n",
      "Epoch: 43\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 43: Loss 0.19235930441193944\n",
      "Epoch: 44\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 44: Loss 0.1921877147288065\n",
      "Epoch: 45\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 45: Loss 0.19202124040724786\n",
      "Epoch: 46\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 46: Loss 0.19185962684981356\n",
      "Epoch: 47\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 47: Loss 0.19170263813658298\n",
      "Epoch: 48\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 48: Loss 0.19155005520461799\n",
      "Epoch: 49\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 49: Loss 0.19140167423963309\n",
      "Epoch: 50\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 50: Loss 0.1912573052518509\n",
      "Epoch: 51\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Epoch 51: Loss 0.19111677081212378\n",
      "Epoch: 52\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 52: Loss 0.1909799049278881\n",
      "Epoch: 53\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 53: Loss 0.19084655204138845\n",
      "Epoch: 54\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 54: Loss 0.190716566135125\n",
      "Epoch: 55\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 55: Loss 0.19058980993153174\n",
      "Epoch: 56\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 56: Loss 0.19046615417566123\n",
      "Epoch: 57\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 57: Loss 0.19034547699123539\n",
      "Epoch: 58\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 58: Loss 0.19022766330160576\n",
      "Epoch: 59\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 59: Loss 0.1901126043082729\n",
      "Epoch: 60\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 60: Loss 0.19000019702062326\n",
      "Epoch: 61\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 61: Loss 0.1898903438312295\n",
      "Epoch: 62\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 62: Loss 0.1897829521317448\n",
      "Epoch: 63\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 63: Loss 0.1896779339651002\n",
      "Epoch: 64\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 64: Loss 0.18957520571000458\n",
      "Epoch: 65\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 65: Loss 0.18947468779448126\n",
      "Epoch: 66\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 66: Loss 0.18937630443514103\n",
      "Epoch: 67\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 67: Loss 0.1892799833996032\n",
      "Epoch: 68\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 68: Loss 0.18918565578956334\n",
      "Epoch: 69\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 69: Loss 0.18909325584222086\n",
      "Epoch: 70\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 70: Loss 0.18900272074818325\n",
      "Epoch: 71\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 71: Loss 0.18891399048400428\n",
      "Epoch: 72\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 72: Loss 0.1888270076577803\n",
      "Epoch: 73\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 73: Loss 0.18874171736640996\n",
      "Epoch: 74\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 74: Loss 0.1886580670632613\n",
      "Epoch: 75\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 75: Loss 0.1885760064350945\n",
      "Epoch: 76\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 76: Loss 0.18849548728730162\n",
      "Epoch: 77\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 77: Loss 0.18841646343659627\n",
      "Epoch: 78\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 78: Loss 0.18833889061045084\n",
      "Epoch: 79\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 79: Loss 0.1882627263524772\n",
      "Epoch: 80\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 80: Loss 0.18818792993343017\n",
      "Epoch: 81\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 81: Loss 0.1881144622671345\n",
      "Epoch: 82\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 82: Loss 0.18804228583102015\n",
      "Epoch: 83\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 83: Loss 0.18797136459094566\n",
      "Epoch: 84\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 84: Loss 0.18790166392984214\n",
      "Epoch: 85\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 85: Loss 0.18783315058012126\n",
      "Epoch: 86\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 86: Loss 0.18776579255945447\n",
      "Epoch: 87\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 87: Loss 0.1876995591097653\n",
      "Epoch: 88\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 88: Loss 0.18763442063933225\n",
      "Epoch: 89\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 89: Loss 0.1875703486676747\n",
      "Epoch: 90\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 90: Loss 0.18750731577328786\n",
      "Epoch: 91\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 91: Loss 0.18744529554389036\n",
      "Epoch: 92\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 92: Loss 0.18738426252923912\n",
      "Epoch: 93\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 93: Loss 0.1873241921962515\n",
      "Epoch: 94\n",
      "Epoch 99: Loss 1\n",
      "Epoch 94: Loss 0.18726506088642644\n",
      "Epoch: 95\n",
      "Epoch 95: Loss 0.18720684577544025\n",
      "Epoch: 96\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 96: Loss 0.18714952483476244\n",
      "Epoch: 97\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Epoch 97: Loss 0.18709307679526324\n",
      "Epoch: 98\n",
      "Epoch 0: Loss 1.0000062181886489\n",
      "Epoch: 1\n",
      "Epoch 98: Loss 0.18703748111272228\n",
      "Epoch: 99\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 99: Loss 0.18698271793508373\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 0\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 0: Loss 0.37627824181987113\n",
      "Epoch: 1\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 1: Loss 0.2558121816986619\n",
      "Epoch: 2\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 2: Loss 0.23680511798870263\n",
      "Epoch: 3\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 3: Loss 0.2274112347652274\n",
      "Epoch: 4\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 4: Loss 0.22153702362531902\n",
      "Epoch: 5\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 5: Loss 0.21741384423537802\n",
      "Epoch: 6\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 6: Loss 0.21431130289438044\n",
      "Epoch: 7\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 7: Loss 0.2118658439847008\n",
      "Epoch: 8\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 8: Loss 0.20987323807868669\n",
      "Epoch: 9\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 9: Loss 0.20820846858864328\n",
      "Epoch: 10\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 10: Loss 0.2067899838995135\n",
      "Epoch: 11\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 11: Loss 0.205561952495719\n",
      "Epoch: 12\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 12: Loss 0.20448468597977243\n",
      "Epoch: 13\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 13: Loss 0.2035291093733321\n",
      "Epoch: 14\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 14: Loss 0.20267338851076805\n",
      "Epoch: 15\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 15: Loss 0.20190077983011573\n",
      "Epoch: 16\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 16: Loss 0.2011982093871973\n",
      "Epoch: 17\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 17: Loss 0.2005553057310508\n",
      "Epoch: 18\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 18: Loss 0.19996372524706993\n",
      "Epoch: 19\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 19: Loss 0.19941667144875314\n",
      "Epoch: 20\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 20: Loss 0.1989085460194826\n",
      "Epoch: 21\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 21: Loss 0.19843469122183763\n",
      "Epoch: 22\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 22: Loss 0.1979911968306329\n",
      "Epoch: 23\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 23: Loss 0.1975747533834638\n",
      "Epoch: 24\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 24: Loss 0.19718253918241865\n",
      "Epoch: 25\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 25: Loss 0.1968121322363012\n",
      "Epoch: 26\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 26: Loss 0.19646144087539713\n",
      "Epoch: 27\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 27: Loss 0.19612864851832398\n",
      "Epoch: 28\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 28: Loss 0.19581216928839298\n",
      "Epoch: 29\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 29: Loss 0.19551061203712966\n",
      "Epoch: 30\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 30: Loss 0.19522275094831093\n",
      "Epoch: 31\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 31: Loss 0.1949475013414413\n",
      "Epoch: 32\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 32: Loss 0.19468389961965335\n",
      "Epoch: 33\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 33: Loss 0.19443108654858512\n",
      "Epoch: 34\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 34: Loss 0.1941882932325708\n",
      "Epoch: 35\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 35: Loss 0.19395482929061955\n",
      "Epoch: 36\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 36: Loss 0.1937300728382328\n",
      "Epoch: 37\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 37: Loss 0.19351346196038938\n",
      "Epoch: 38\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 38: Loss 0.19330448742303805\n",
      "Epoch: 39\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 39: Loss 0.19310268641854766\n",
      "Epoch: 40\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 40: Loss 0.19290763717853837\n",
      "Epoch: 41\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 41: Loss 0.19271895431785277\n",
      "Epoch: 42\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 42: Loss 0.1925362847972406\n",
      "Epoch: 43\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 43: Loss 0.19235930441193944\n",
      "Epoch: 44\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 44: Loss 0.1921877147288065\n",
      "Epoch: 45\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 45: Loss 0.19202124040724786\n",
      "Epoch: 46\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 46: Loss 0.19185962684981356\n",
      "Epoch: 47\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 47: Loss 0.19170263813658298\n",
      "Epoch: 48\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 48: Loss 0.19155005520461799\n",
      "Epoch: 49\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 49: Loss 0.19140167423963309\n",
      "Epoch: 50\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 50: Loss 0.1912573052518509\n",
      "Epoch: 51\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 51: Loss 0.19111677081212378\n",
      "Epoch: 52\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 52: Loss 0.1909799049278881\n",
      "Epoch: 53\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 53: Loss 0.19084655204138845\n",
      "Epoch: 54\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 54: Loss 0.190716566135125\n",
      "Epoch: 55\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 55: Loss 0.19058980993153174\n",
      "Epoch: 56\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 56: Loss 0.19046615417566123\n",
      "Epoch: 57\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 57: Loss 0.19034547699123539\n",
      "Epoch: 58\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 58: Loss 0.19022766330160576\n",
      "Epoch: 59\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 59: Loss 0.1901126043082729\n",
      "Epoch: 60\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 60: Loss 0.19000019702062326\n",
      "Epoch: 61\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 61: Loss 0.1898903438312295\n",
      "Epoch: 62\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 62: Loss 0.1897829521317448\n",
      "Epoch: 63\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 63: Loss 0.1896779339651002\n",
      "Epoch: 64\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 64: Loss 0.18957520571000458\n",
      "Epoch: 65\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 65: Loss 0.18947468779448126\n",
      "Epoch: 66\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 66: Loss 0.18937630443514103\n",
      "Epoch: 67\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 67: Loss 0.1892799833996032\n",
      "Epoch: 68\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 68: Loss 0.18918565578956334\n",
      "Epoch: 69\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 69: Loss 0.18909325584222086\n",
      "Epoch: 70\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 70: Loss 0.18900272074818325\n",
      "Epoch: 71\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 71: Loss 0.18891399048400428\n",
      "Epoch: 72\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 72: Loss 0.1888270076577803\n",
      "Epoch: 73\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 73: Loss 0.18874171736640996\n",
      "Epoch: 74\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 74: Loss 0.1886580670632613\n",
      "Epoch: 75\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 75: Loss 0.1885760064350945\n",
      "Epoch: 76\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 76: Loss 0.18849548728730162\n",
      "Epoch: 77\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 77: Loss 0.18841646343659627\n",
      "Epoch: 78\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 78: Loss 0.18833889061045084\n",
      "Epoch: 79\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 79: Loss 0.1882627263524772\n",
      "Epoch: 80\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 80: Loss 0.18818792993343017\n",
      "Epoch: 81\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 81: Loss 0.1881144622671345\n",
      "Epoch: 82\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 82: Loss 0.18804228583102015\n",
      "Epoch: 83\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 83: Loss 0.18797136459094566\n",
      "Epoch: 84\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 84: Loss 0.18790166392984214\n",
      "Epoch: 85\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 85: Loss 0.18783315058012126\n",
      "Epoch: 86\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 86: Loss 0.18776579255945447\n",
      "Epoch: 87\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 87: Loss 0.1876995591097653\n",
      "Epoch: 88\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 88: Loss 0.18763442063933225\n",
      "Epoch: 89\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 89: Loss 0.1875703486676747\n",
      "Epoch: 90\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 90: Loss 0.18750731577328786\n",
      "Epoch: 91\n",
      "Epoch 99: Loss 1\n",
      "Epoch 91: Loss 0.18744529554389036\n",
      "Epoch: 92\n",
      "Epoch 92: Loss 0.18738426252923912\n",
      "Epoch: 93\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }] }\n",
      "Epoch: 0\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 93: Loss 0.1873241921962515\n",
      "Epoch: 94\n",
      "Epoch 0: Loss 0.37627824181987113\n",
      "Epoch: 1\n",
      "Epoch 94: Loss 0.18726506088642644\n",
      "Epoch: 95\n",
      "Epoch 1: Loss 0.2558121816986619\n",
      "Epoch: 2\n",
      "Epoch 95: Loss 0.18720684577544025\n",
      "Epoch: 96\n",
      "Epoch 2: Loss 0.23680511798870263\n",
      "Epoch: 3\n",
      "Epoch 96: Loss 0.18714952483476244\n",
      "Epoch: 97\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 3: Loss 0.2274112347652274\n",
      "Epoch: 4\n",
      "Epoch 97: Loss 0.18709307679526324\n",
      "Epoch: 98\n",
      "Epoch 4: Loss 0.22153702362531902\n",
      "Epoch: 5\n",
      "Epoch 98: Loss 0.18703748111272228\n",
      "Epoch: 99\n",
      "Epoch 5: Loss 0.21741384423537802\n",
      "Epoch: 6\n",
      "Epoch 99: Loss 0.18698271793508373\n",
      "Epoch 6: Loss 0.21431130289438044\n",
      "Epoch: 7\n",
      "Epoch 7: Loss 0.2118658439847008\n",
      "Epoch: 8\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 10, output_size: 713 }, activation: Tanh }, LayerShape { layer_type: Dense { input_size: 713, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Epoch 8: Loss 0.20987323807868669\n",
      "Epoch: 9\n",
      "Epoch 9: Loss 0.20820846858864328\n",
      "Epoch: 10\n",
      "Epoch 10: Loss 0.2067899838995135\n",
      "Epoch: 11\n",
      "Epoch 11: Loss 0.205561952495719\n",
      "Epoch: 12\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 12: Loss 0.20448468597977243\n",
      "Epoch: 13\n",
      "Epoch 13: Loss 0.2035291093733321\n",
      "Epoch: 14\n",
      "Epoch 14: Loss 0.20267338851076805\n",
      "Epoch: 15\n",
      "Epoch 15: Loss 0.20190077983011573\n",
      "Epoch: 16\n",
      "Epoch 16: Loss 0.2011982093871973\n",
      "Epoch: 17\n",
      "Epoch 17: Loss 0.2005553057310508\n",
      "Epoch: 18\n",
      "Epoch 18: Loss 0.19996372524706993\n",
      "Epoch: 19\n",
      "Epoch 19: Loss 0.19941667144875314\n",
      "Epoch: 20\n",
      "Epoch 20: Loss 0.1989085460194826\n",
      "Epoch: 21\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 0: Loss 1.0000014651653886\n",
      "Epoch: 1\n",
      "Epoch 21: Loss 0.19843469122183763\n",
      "Epoch: 22\n",
      "Epoch 22: Loss 0.1979911968306329\n",
      "Epoch: 23\n",
      "Epoch 23: Loss 0.1975747533834638\n",
      "Epoch: 24\n",
      "Epoch 24: Loss 0.19718253918241865\n",
      "Epoch: 25\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 25: Loss 0.1968121322363012\n",
      "Epoch: 26\n",
      "Epoch 26: Loss 0.19646144087539713\n",
      "Epoch: 27\n",
      "Epoch 27: Loss 0.19612864851832398\n",
      "Epoch: 28\n",
      "Epoch 28: Loss 0.19581216928839298\n",
      "Epoch: 29\n",
      "Epoch 29: Loss 0.19551061203712966\n",
      "Epoch: 30\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 30: Loss 0.19522275094831093\n",
      "Epoch: 31\n",
      "Epoch 31: Loss 0.1949475013414413\n",
      "Epoch: 32\n",
      "Epoch 32: Loss 0.19468389961965335\n",
      "Epoch: 33\n",
      "Epoch 33: Loss 0.19443108654858512\n",
      "Epoch: 34\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 34: Loss 0.1941882932325708\n",
      "Epoch: 35\n",
      "Epoch 35: Loss 0.19395482929061955\n",
      "Epoch: 36\n",
      "Epoch 36: Loss 0.1937300728382328\n",
      "Epoch: 37\n",
      "Epoch 37: Loss 0.19351346196038938\n",
      "Epoch: 38\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 38: Loss 0.19330448742303805\n",
      "Epoch: 39\n",
      "Epoch 39: Loss 0.19310268641854766\n",
      "Epoch: 40\n",
      "Epoch 40: Loss 0.19290763717853837\n",
      "Epoch: 41\n",
      "Epoch 41: Loss 0.19271895431785277\n",
      "Epoch: 42\n",
      "Epoch 42: Loss 0.1925362847972406\n",
      "Epoch: 43\n",
      "Epoch 43: Loss 0.19235930441193944\n",
      "Epoch: 44\n",
      "Epoch 44: Loss 0.1921877147288065\n",
      "Epoch: 45\n",
      "Epoch 45: Loss 0.19202124040724786\n",
      "Epoch: 46\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 46: Loss 0.19185962684981356\n",
      "Epoch: 47\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 47: Loss 0.19170263813658298\n",
      "Epoch: 48\n",
      "Epoch 48: Loss 0.19155005520461799\n",
      "Epoch: 49\n",
      "Epoch 49: Loss 0.19140167423963309\n",
      "Epoch: 50\n",
      "Epoch 50: Loss 0.1912573052518509\n",
      "Epoch: 51\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 51: Loss 0.19111677081212378\n",
      "Epoch: 52\n",
      "Epoch 52: Loss 0.1909799049278881\n",
      "Epoch: 53\n",
      "Epoch 53: Loss 0.19084655204138845\n",
      "Epoch: 54\n",
      "Epoch 54: Loss 0.190716566135125\n",
      "Epoch: 55\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 55: Loss 0.19058980993153174\n",
      "Epoch: 56\n",
      "Epoch 56: Loss 0.19046615417566123\n",
      "Epoch: 57\n",
      "Epoch 57: Loss 0.19034547699123539\n",
      "Epoch: 58\n",
      "Epoch 58: Loss 0.19022766330160576\n",
      "Epoch: 59\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Epoch 59: Loss 0.1901126043082729\n",
      "Epoch: 60\n",
      "Epoch 60: Loss 0.19000019702062326\n",
      "Epoch: 61\n",
      "Epoch 61: Loss 0.1898903438312295\n",
      "Epoch: 62\n",
      "Epoch 62: Loss 0.1897829521317448\n",
      "Epoch: 63\n",
      "Epoch 63: Loss 0.1896779339651002\n",
      "Epoch: 64\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 64: Loss 0.18957520571000458\n",
      "Epoch: 65\n",
      "Epoch 65: Loss 0.18947468779448126\n",
      "Epoch: 66\n",
      "Epoch 66: Loss 0.18937630443514103\n",
      "Epoch: 67\n",
      "Epoch 67: Loss 0.1892799833996032\n",
      "Epoch: 68\n",
      "Epoch 68: Loss 0.18918565578956334\n",
      "Epoch: 69\n",
      "Epoch 69: Loss 0.18909325584222086\n",
      "Epoch: 70\n",
      "Epoch 70: Loss 0.18900272074818325\n",
      "Epoch: 71\n",
      "Epoch 71: Loss 0.18891399048400428\n",
      "Epoch: 72\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 72: Loss 0.1888270076577803\n",
      "Epoch: 73\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 73: Loss 0.18874171736640996\n",
      "Epoch: 74\n",
      "Epoch 74: Loss 0.1886580670632613\n",
      "Epoch: 75\n",
      "Epoch 75: Loss 0.1885760064350945\n",
      "Epoch: 76\n",
      "Epoch 76: Loss 0.18849548728730162\n",
      "Epoch: 77\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 77: Loss 0.18841646343659627\n",
      "Epoch: 78\n",
      "Epoch 78: Loss 0.18833889061045084\n",
      "Epoch: 79\n",
      "Epoch 79: Loss 0.1882627263524772\n",
      "Epoch: 80\n",
      "Epoch 80: Loss 0.18818792993343017\n",
      "Epoch: 81\n",
      "Epoch 81: Loss 0.1881144622671345\n",
      "Epoch: 82\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 82: Loss 0.18804228583102015\n",
      "Epoch: 83\n",
      "Epoch 83: Loss 0.18797136459094566\n",
      "Epoch: 84\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 84: Loss 0.18790166392984214\n",
      "Epoch: 85\n",
      "Epoch 85: Loss 0.18783315058012126\n",
      "Epoch: 86\n",
      "Epoch 86: Loss 0.18776579255945447\n",
      "Epoch: 87\n",
      "Epoch 87: Loss 0.1876995591097653\n",
      "Epoch: 88\n",
      "Epoch 88: Loss 0.18763442063933225\n",
      "Epoch: 89\n",
      "Epoch 89: Loss 0.1875703486676747\n",
      "Epoch: 90\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 90: Loss 0.18750731577328786\n",
      "Epoch: 91\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 91: Loss 0.18744529554389036\n",
      "Epoch: 92\n",
      "Epoch 92: Loss 0.18738426252923912\n",
      "Epoch: 93\n",
      "Epoch 93: Loss 0.1873241921962515\n",
      "Epoch: 94\n",
      "Epoch 94: Loss 0.18726506088642644\n",
      "Epoch: 95\n",
      "Epoch 95: Loss 0.18720684577544025\n",
      "Epoch: 96\n",
      "Epoch 96: Loss 0.18714952483476244\n",
      "Epoch: 97\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 97: Loss 0.18709307679526324\n",
      "Epoch: 98\n",
      "Epoch 98: Loss 0.18703748111272228\n",
      "Epoch: 99\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 99: Loss 0.18698271793508373\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Sigmoid }, LayerShape { layer_type: Dense { input_size: 10, output_size: 1020 }, activation: Tanh }, LayerShape { layer_type: Dense { input_size: 1020, output_size: 10 }, activation: ReLU }] }\n",
      "Epoch: 0\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 0: Loss 1.0000007105352302\n",
      "Epoch: 1\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 1: Loss 1\n",
      "Epoch: 2\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 2: Loss 1\n",
      "Epoch: 3\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 3: Loss 1\n",
      "Epoch: 4\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 4: Loss 1\n",
      "Epoch: 5\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 5: Loss 1\n",
      "Epoch: 6\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 6: Loss 1\n",
      "Epoch: 7\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 7: Loss 1\n",
      "Epoch: 8\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 8: Loss 1\n",
      "Epoch: 9\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 9: Loss 1\n",
      "Epoch: 10\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 10: Loss 1\n",
      "Epoch: 11\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 11: Loss 1\n",
      "Epoch: 12\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 12: Loss 1\n",
      "Epoch: 13\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 13: Loss 1\n",
      "Epoch: 14\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 14: Loss 1\n",
      "Epoch: 15\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 15: Loss 1\n",
      "Epoch: 16\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 16: Loss 1\n",
      "Epoch: 17\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 17: Loss 1\n",
      "Epoch: 18\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 18: Loss 1\n",
      "Epoch: 19\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 19: Loss 1\n",
      "Epoch: 20\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 20: Loss 1\n",
      "Epoch: 21\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 21: Loss 1\n",
      "Epoch: 22\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 22: Loss 1\n",
      "Epoch: 23\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 23: Loss 1\n",
      "Epoch: 24\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 24: Loss 1\n",
      "Epoch: 25\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 25: Loss 1\n",
      "Epoch: 26\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 26: Loss 1\n",
      "Epoch: 27\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 27: Loss 1\n",
      "Epoch: 28\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 28: Loss 1\n",
      "Epoch: 29\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 29: Loss 1\n",
      "Epoch: 30\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 30: Loss 1\n",
      "Epoch: 31\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 31: Loss 1\n",
      "Epoch: 32\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 99: Loss 1\n",
      "Inputs: 59999 x 196\n",
      "Targets: 59999 x 10\n",
      "Training neural network with shape: NeuralNetworkShape { layers: [LayerShape { layer_type: Dense { input_size: 196, output_size: 10 }, activation: Tanh }] }\n",
      "Epoch: 0\n",
      "Epoch 0: Loss 1.6912345885583506\n",
      "Epoch: 1\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 32: Loss 1\n",
      "Epoch: 33\n",
      "Epoch 1: Loss 1.6592057724881988\n",
      "Epoch: 2\n",
      "Epoch 2: Loss 1.6495943780772515\n",
      "Epoch: 3\n",
      "Epoch 3: Loss 1.6460033857554708\n",
      "Epoch: 4\n",
      "Epoch 4: Loss 1.6438282035787197\n",
      "Epoch: 5\n",
      "Epoch 5: Loss 1.6410011009212084\n",
      "Epoch: 6\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 6: Loss 1.6392046955581716\n",
      "Epoch: 7\n",
      "Epoch 7: Loss 1.6393439131505512\n",
      "Epoch: 8\n",
      "Epoch 8: Loss 1.6376763219892372\n",
      "Epoch: 9\n",
      "Epoch 9: Loss 1.6391098026063216\n",
      "Epoch: 10\n",
      "Epoch 10: Loss 1.638222863415296\n",
      "Epoch: 11\n",
      "Epoch 11: Loss 1.6376158914057326\n",
      "Epoch: 12\n",
      "Epoch 12: Loss 1.6358148973749995\n",
      "Epoch: 13\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 13: Loss 1.6361807713734935\n",
      "Epoch: 14\n",
      "Epoch 14: Loss 1.637325995474375\n",
      "Epoch: 15\n",
      "Epoch 15: Loss 1.6339465451111497\n",
      "Epoch: 16\n",
      "Epoch 16: Loss 1.6336206635553243\n",
      "Epoch: 17\n",
      "Epoch 17: Loss 1.6368676396644237\n",
      "Epoch: 18\n",
      "Epoch 33: Loss 1\n",
      "Epoch: 34\n",
      "Epoch 18: Loss 1.6366854368341774\n",
      "Epoch: 19\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 19: Loss 1.6361306726605946\n",
      "Epoch: 20\n",
      "Epoch 20: Loss 1.6329737193069265\n",
      "Epoch: 21\n",
      "Epoch 21: Loss 1.6342461540980189\n",
      "Epoch: 22\n",
      "Epoch 22: Loss 1.6357178981150595\n",
      "Epoch: 23\n",
      "Epoch 23: Loss 1.6307446690385583\n",
      "Epoch: 24\n",
      "Epoch 24: Loss 1.6344295677148806\n",
      "Epoch: 25\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 25: Loss 1.6328367227423353\n",
      "Epoch: 26\n",
      "Epoch 26: Loss 1.6355202264516326\n",
      "Epoch: 27\n",
      "Epoch 27: Loss 1.632953636127348\n",
      "Epoch: 28\n",
      "Epoch 28: Loss 1.6325371928634762\n",
      "Epoch: 29\n",
      "Epoch 29: Loss 1.6322740639654223\n",
      "Epoch: 30\n",
      "Epoch 30: Loss 1.6329480203244677\n",
      "Epoch: 31\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 31: Loss 1.6306992816097108\n",
      "Epoch: 32\n",
      "Epoch 32: Loss 1.634847935544994\n",
      "Epoch: 33\n",
      "Epoch 33: Loss 1.6315534016494495\n",
      "Epoch: 34\n",
      "Epoch 34: Loss 1.632327541625946\n",
      "Epoch: 35\n",
      "Epoch 34: Loss 1\n",
      "Epoch: 35\n",
      "Epoch 35: Loss 1.6358239038919116\n",
      "Epoch: 36\n",
      "Epoch 36: Loss 1.6327678958616314\n",
      "Epoch: 37\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 37: Loss 1.6313980226100697\n",
      "Epoch: 38\n",
      "Epoch 38: Loss 1.6320300409457764\n",
      "Epoch: 39\n",
      "Epoch 39: Loss 1.633475111927439\n",
      "Epoch: 40\n",
      "Epoch 40: Loss 1.633720292056021\n",
      "Epoch: 41\n",
      "Epoch 41: Loss 1.6346622473861558\n",
      "Epoch: 42\n",
      "Epoch 42: Loss 1.6314185486577901\n",
      "Epoch: 43\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 43: Loss 1.6330502511283145\n",
      "Epoch: 44\n",
      "Epoch 44: Loss 1.6328615847104442\n",
      "Epoch: 45\n",
      "Epoch 45: Loss 1.630928186289043\n",
      "Epoch: 46\n",
      "Epoch 46: Loss 1.6310596280939904\n",
      "Epoch: 47\n",
      "Epoch 47: Loss 1.6324760663443012\n",
      "Epoch: 48\n",
      "Epoch 48: Loss 1.6320079938225198\n",
      "Epoch: 49\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 49: Loss 1.6312253813759323\n",
      "Epoch: 50\n",
      "Epoch 50: Loss 1.635659543791591\n",
      "Epoch: 51\n",
      "Epoch 35: Loss 1\n",
      "Epoch: 36\n",
      "Epoch 51: Loss 1.633618993782175\n",
      "Epoch: 52\n",
      "Epoch 52: Loss 1.6324539360386963\n",
      "Epoch: 53\n",
      "Epoch 53: Loss 1.6306817264621774\n",
      "Epoch: 54\n",
      "Epoch 54: Loss 1.632635867420305\n",
      "Epoch: 55\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 55: Loss 1.6323499930967722\n",
      "Epoch: 56\n",
      "Epoch 56: Loss 1.6323583728405593\n",
      "Epoch: 57\n",
      "Epoch 57: Loss 1.6326692435317955\n",
      "Epoch: 58\n",
      "Epoch 58: Loss 1.6329743359867925\n",
      "Epoch: 59\n",
      "Epoch 59: Loss 1.6317939313780538\n",
      "Epoch: 60\n",
      "Epoch 60: Loss 1.6345919321228122\n",
      "Epoch: 61\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 61: Loss 1.6313932152969892\n",
      "Epoch: 62\n",
      "Epoch 62: Loss 1.6319989869305682\n",
      "Epoch: 63\n",
      "Epoch 63: Loss 1.6335497954365639\n",
      "Epoch: 64\n",
      "Epoch 64: Loss 1.6334620821592925\n",
      "Epoch: 65\n",
      "Epoch 65: Loss 1.6330232888440865\n",
      "Epoch: 66\n",
      "Epoch 66: Loss 1.633347773318737\n",
      "Epoch: 67\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 67: Loss 1.6314441946514486\n",
      "Epoch: 68\n",
      "Epoch 36: Loss 1\n",
      "Epoch: 37\n",
      "Epoch 68: Loss 1.6357440276663835\n",
      "Epoch: 69\n",
      "Epoch 69: Loss 1.6324622788717544\n",
      "Epoch: 70\n",
      "Epoch 70: Loss 1.631758911221974\n",
      "Epoch: 71\n",
      "Epoch 71: Loss 1.6312521315082207\n",
      "Epoch: 72\n",
      "Epoch 72: Loss 1.6341248518080436\n",
      "Epoch: 73\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 73: Loss 1.6329031478367555\n",
      "Epoch: 74\n",
      "Epoch 74: Loss 1.6326074737446785\n",
      "Epoch: 75\n",
      "Epoch 75: Loss 1.6325674476311536\n",
      "Epoch: 76\n",
      "Epoch 76: Loss 1.632497869047631\n",
      "Epoch: 77\n",
      "Epoch 77: Loss 1.6337660469726023\n",
      "Epoch: 78\n",
      "Epoch 78: Loss 1.6335797037355675\n",
      "Epoch: 79\n",
      "Epoch 79: Loss 1.6330245647139408\n",
      "Epoch: 80\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 80: Loss 1.6314703396832193\n",
      "Epoch: 81\n",
      "Epoch 81: Loss 1.633022017632895\n",
      "Epoch: 82\n",
      "Epoch 82: Loss 1.632684275623023\n",
      "Epoch: 83\n",
      "Epoch 83: Loss 1.631018751471861\n",
      "Epoch: 84\n",
      "Epoch 84: Loss 1.6305190069826467\n",
      "Epoch: 85\n",
      "Epoch 37: Loss 1\n",
      "Epoch: 38\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 85: Loss 1.6329925068540792\n",
      "Epoch: 86\n",
      "Epoch 86: Loss 1.63309226382484\n",
      "Epoch: 87\n",
      "Epoch 87: Loss 1.631375197407091\n",
      "Epoch: 88\n",
      "Epoch 88: Loss 1.6335014811614026\n",
      "Epoch: 89\n",
      "Epoch 89: Loss 1.6325999579106025\n",
      "Epoch: 90\n",
      "Epoch 90: Loss 1.6321356728048384\n",
      "Epoch: 91\n",
      "Epoch 91: Loss 1.6331890743821504\n",
      "Epoch: 92\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 92: Loss 1.6329750316677698\n",
      "Epoch: 93\n",
      "Epoch 93: Loss 1.6306554391880195\n",
      "Epoch: 94\n",
      "Epoch 94: Loss 1.6305896574358014\n",
      "Epoch: 95\n",
      "Epoch 95: Loss 1.6307169067301606\n",
      "Epoch: 96\n",
      "Epoch 96: Loss 1.6322770327071228\n",
      "Epoch: 97\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 97: Loss 1.633032838165433\n",
      "Epoch: 98\n",
      "Epoch 98: Loss 1.6308609816258226\n",
      "Epoch: 99\n",
      "Epoch 99: Loss 1.6328580081900117\n",
      "Epoch 38: Loss 1\n",
      "Epoch: 39\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 39: Loss 1\n",
      "Epoch: 40\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 40: Loss 1\n",
      "Epoch: 41\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 41: Loss 1\n",
      "Epoch: 42\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 42: Loss 1\n",
      "Epoch: 43\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 43: Loss 1\n",
      "Epoch: 44\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 44: Loss 1\n",
      "Epoch: 45\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 45: Loss 1\n",
      "Epoch: 46\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 46: Loss 1\n",
      "Epoch: 47\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 47: Loss 1\n",
      "Epoch: 48\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 48: Loss 1\n",
      "Epoch: 49\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 49: Loss 1\n",
      "Epoch: 50\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 50: Loss 1\n",
      "Epoch: 51\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 51: Loss 1\n",
      "Epoch: 52\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 52: Loss 1\n",
      "Epoch: 53\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 53: Loss 1\n",
      "Epoch: 54\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 54: Loss 1\n",
      "Epoch: 55\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 55: Loss 1\n",
      "Epoch: 56\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 99: Loss 1\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 56: Loss 1\n",
      "Epoch: 57\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 57: Loss 1\n",
      "Epoch: 58\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 58: Loss 1\n",
      "Epoch: 59\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 59: Loss 1\n",
      "Epoch: 60\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 60: Loss 1\n",
      "Epoch: 61\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 61: Loss 1\n",
      "Epoch: 62\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 62: Loss 1\n",
      "Epoch: 63\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 63: Loss 1\n",
      "Epoch: 64\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 64: Loss 1\n",
      "Epoch: 65\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 65: Loss 1\n",
      "Epoch: 66\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 66: Loss 1\n",
      "Epoch: 67\n",
      "Epoch 99: Loss 1\n",
      "Epoch 67: Loss 1\n",
      "Epoch: 68\n",
      "Epoch 68: Loss 1\n",
      "Epoch: 69\n",
      "Epoch 69: Loss 1\n",
      "Epoch: 70\n",
      "Epoch 70: Loss 1\n",
      "Epoch: 71\n",
      "Epoch 71: Loss 1\n",
      "Epoch: 72\n",
      "Epoch 72: Loss 1\n",
      "Epoch: 73\n",
      "Epoch 73: Loss 1\n",
      "Epoch: 74\n",
      "Epoch 74: Loss 1\n",
      "Epoch: 75\n",
      "Epoch 75: Loss 1\n",
      "Epoch: 76\n",
      "Epoch 76: Loss 1\n",
      "Epoch: 77\n",
      "Epoch 77: Loss 1\n",
      "Epoch: 78\n",
      "Epoch 78: Loss 1\n",
      "Epoch: 79\n",
      "Epoch 79: Loss 1\n",
      "Epoch: 80\n",
      "Epoch 80: Loss 1\n",
      "Epoch: 81\n",
      "Epoch 81: Loss 1\n",
      "Epoch: 82\n",
      "Epoch 82: Loss 1\n",
      "Epoch: 83\n",
      "Epoch 83: Loss 1\n",
      "Epoch: 84\n",
      "Epoch 84: Loss 1\n",
      "Epoch: 85\n",
      "Epoch 85: Loss 1\n",
      "Epoch: 86\n",
      "Epoch 86: Loss 1\n",
      "Epoch: 87\n",
      "Epoch 87: Loss 1\n",
      "Epoch: 88\n",
      "Epoch 88: Loss 1\n",
      "Epoch: 89\n",
      "Epoch 89: Loss 1\n",
      "Epoch: 90\n",
      "Epoch 90: Loss 1\n",
      "Epoch: 91\n",
      "Epoch 91: Loss 1\n",
      "Epoch: 92\n",
      "Epoch 92: Loss 1\n",
      "Epoch: 93\n",
      "Epoch 93: Loss 1\n",
      "Epoch: 94\n",
      "Epoch 94: Loss 1\n",
      "Epoch: 95\n",
      "Epoch 95: Loss 1\n",
      "Epoch: 96\n",
      "Epoch 96: Loss 1\n",
      "Epoch: 97\n",
      "Epoch 97: Loss 1\n",
      "Epoch: 98\n",
      "Epoch 98: Loss 1\n",
      "Epoch: 99\n",
      "Epoch 99: Loss 1\n",
      "Generation: 0\n",
      "Error occurred during model training: Command '['./nn_generator', '--model-directory', './trained_model', '--input-file', 'input.csv', '--target-file', 'target.csv', '--training-verification-ratio', '0.7', '--learning-rate', '0.01', '--epochs', '100', '--tolerance', '0.1', '--num-generations', '100', '--log-level', '1', '--population-size', '4', '--num-offsprings', '10']' returned non-zero exit status 101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread 'main' panicked at src/neural/nn/neuralnet.rs:328:50:\n",
      "index out of bounds: the len is 0 but the index is 0\n",
      "stack backtrace:\n",
      "   0: rust_begin_unwind\n",
      "   1: core::panicking::panic_fmt\n",
      "   2: core::panicking::panic_bounds_check\n",
      "   3: learn::neural::nn::neuralnet::NeuralNetwork::get_subnetwork\n",
      "   4: <learn::gen::pheno::nn_pheno::NeuralNetworkPhenotype as learn::evol::phenotype::Phenotype>::crossover\n",
      "   5: <learn::evol::strategy::ordinary::OrdinaryStrategy as learn::evol::strategy::BreedStrategy<Pheno>>::breed\n",
      "   6: <learn::gen::strategy::nn_strategy::NeuralNetworkStrategy as learn::evol::strategy::BreedStrategy<learn::gen::pheno::nn_pheno::NeuralNetworkPhenotype>>::breed\n",
      "   7: learn::evol::evolution::parallel_launcher::ParallelEvolutionLauncher<Pheno,Strategy,Chall>::evolve\n",
      "   8: learn::gen::neuralnet_gen::NeuralNetworkGenerator::generate\n",
      "   9: nn_generator::main\n",
      "note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define parameters for `nn_generator`\n",
    "model_directory = \"./trained_model\"\n",
    "# create the trained model directory\n",
    "import os\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "input_file = \"input.csv\"\n",
    "target_file = \"target.csv\"\n",
    "training_verification_ratio = 0.7\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "tolerance = 0.1\n",
    "num_generations = 100\n",
    "log_level = 1\n",
    "population_size = 4\n",
    "num_offsprings = 10\n",
    "\n",
    "# Create the command for training the neural network\n",
    "command = [\n",
    "    \"./nn_generator\",\n",
    "    \"--model-directory\", model_directory,\n",
    "    \"--input-file\", input_file,\n",
    "    \"--target-file\", target_file,\n",
    "    \"--training-verification-ratio\", str(training_verification_ratio),\n",
    "    \"--learning-rate\", str(learning_rate),\n",
    "    \"--epochs\", str(epochs),\n",
    "    \"--tolerance\", str(tolerance),\n",
    "    \"--num-generations\", str(num_generations),\n",
    "    \"--log-level\", str(log_level),\n",
    "    \"--population-size\", str(population_size),\n",
    "    \"--num-offsprings\", str(num_offsprings)\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "try:\n",
    "    #subprocess.run(command, check=True)\n",
    "    # Create a copy of the current environment variables and add RUST_BACKTRACE=1\n",
    "    env = os.environ.copy()\n",
    "    env[\"RUST_BACKTRACE\"] = \"1\"\n",
    "\n",
    "    # Run the command\n",
    "    subprocess.run(command, check=True, env=env)\n",
    "    print(\"Model training completed successfully and saved in:\", model_directory)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error occurred during model training:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827f8e5",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5477d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x_test_flat, y_test_onehot)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(x_test_flat, y_test_onehot)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
